{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7494538f5c5217cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Codio Activity 23.3: Using a Pre-trained Network\n",
    "\n",
    "**Expected Time = 90 minutes**\n",
    "\n",
    "**Total Points = 50**\n",
    "\n",
    "This activity introduces the use of a pretrained network with `keras`.  There are many available models, but you will use one that can be fit with smaller image examples.  To do so, you will use the `EfficientNetV2B0` model with the `cifar10` dataset from `keras`.  \n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)\n",
    "\n",
    "Run the code cell below to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T06:46:43.834718Z",
     "start_time": "2024-03-08T06:46:39.850930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Java\\Python3.10.8\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B0\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05a4386981a0d073",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Information on the Model and Dataset\n",
    "\n",
    "For more information on the model you can consult the paper from its origin [here](https://arxiv.org/abs/1905.11946) and the `keras` documentation on the model [here](https://keras.io/api/applications/efficientnet/).  For your purposes, keep in mind that this model has been trained on 1000 image classes and you will use the resulting feature maps to transform the `cifar10` data.\n",
    "\n",
    "**The Data**\n",
    "\n",
    "This dataset contains 50,000 32x32 color training images and 10,000 test images, labeled over 10 categories. \n",
    "\n",
    "The categories are:\n",
    "\n",
    "|Label\t|Description|\n",
    "| ------ | ------- |\n",
    "|0\t|airplane|\n",
    "|1\t|automobile|\n",
    "|2\t|bird|\n",
    "|3\t|cat|\n",
    "|4\t|deer|\n",
    "|5\t|dog|\n",
    "|6\t|frog|\n",
    "|7\t|horse|\n",
    "|8\t|ship|\n",
    "|9\t|truck|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dc7213c4ec382a15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Dowloading the model\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Below, use the `EfficientNetV2B0` function with the appropriate  `input_shape` and the argument `include_top` equal to `False` to load the base model. Assign your result to the variable `base_model`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba5744db3c86b792",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T06:52:17.549423Z",
     "start_time": "2024-03-08T06:52:13.486092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 893217f2bb855e2983157299931e43ff so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
      "18112512/24274472 [=====================>........] - ETA: 0s"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incomplete or corrupted file detected. The auto file hash does not match the provided value of 893217f2bb855e2983157299931e43ff.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m### BEGIN SOLUTION\u001B[39;00m\n\u001B[0;32m      7\u001B[0m tf\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mset_seed(\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m----> 8\u001B[0m base_model \u001B[38;5;241m=\u001B[39m \u001B[43mEfficientNetV2B0\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_top\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m### END SOLUTION\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m### ANSWER CHECK\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(base_model)\n",
      "File \u001B[1;32mC:\\Java\\Python3.10.8\\lib\\site-packages\\keras\\src\\applications\\efficientnet_v2.py:1130\u001B[0m, in \u001B[0;36mEfficientNetV2B0\u001B[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, include_preprocessing)\u001B[0m\n\u001B[0;32m   1116\u001B[0m \u001B[38;5;129m@keras_export\u001B[39m(\n\u001B[0;32m   1117\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras.applications.efficientnet_v2.EfficientNetV2B0\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1118\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras.applications.EfficientNetV2B0\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1128\u001B[0m     include_preprocessing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m   1129\u001B[0m ):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mEfficientNetV2\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1131\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwidth_coefficient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1132\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdepth_coefficient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1133\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdefault_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m224\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1134\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mefficientnetv2-b0\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1135\u001B[0m \u001B[43m        \u001B[49m\u001B[43minclude_top\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_top\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1136\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1137\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_tensor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1138\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_shape\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1139\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpooling\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpooling\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1140\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclasses\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclasses\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1141\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclassifier_activation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclassifier_activation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1142\u001B[0m \u001B[43m        \u001B[49m\u001B[43minclude_preprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_preprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1143\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Java\\Python3.10.8\\lib\\site-packages\\keras\\src\\applications\\efficientnet_v2.py:1103\u001B[0m, in \u001B[0;36mEfficientNetV2\u001B[1;34m(width_coefficient, depth_coefficient, default_size, dropout_rate, drop_connect_rate, depth_divisor, min_depth, bn_momentum, activation, blocks_args, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, include_preprocessing)\u001B[0m\n\u001B[0;32m   1101\u001B[0m         file_hash \u001B[38;5;241m=\u001B[39m WEIGHTS_HASHES[model_name[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m:]][\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   1102\u001B[0m     file_name \u001B[38;5;241m=\u001B[39m model_name \u001B[38;5;241m+\u001B[39m file_suffix\n\u001B[1;32m-> 1103\u001B[0m     weights_path \u001B[38;5;241m=\u001B[39m \u001B[43mdata_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1104\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfile_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1105\u001B[0m \u001B[43m        \u001B[49m\u001B[43mBASE_WEIGHTS_PATH\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mfile_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1106\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_subdir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodels\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1107\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfile_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfile_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1108\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1109\u001B[0m     model\u001B[38;5;241m.\u001B[39mload_weights(weights_path)\n\u001B[0;32m   1110\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m weights \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mC:\\Java\\Python3.10.8\\lib\\site-packages\\keras\\src\\utils\\data_utils.py:362\u001B[0m, in \u001B[0;36mget_file\u001B[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001B[0m\n\u001B[0;32m    360\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(fpath) \u001B[38;5;129;01mand\u001B[39;00m file_hash \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    361\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m validate_file(fpath, file_hash, algorithm\u001B[38;5;241m=\u001B[39mhash_algorithm):\n\u001B[1;32m--> 362\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    363\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIncomplete or corrupted file detected. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    364\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhash_algorithm\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    365\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile hash does not match the provided value \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    366\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_hash\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    367\u001B[0m             )\n\u001B[0;32m    369\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m untar:\n\u001B[0;32m    370\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(untar_fpath):\n",
      "\u001B[1;31mValueError\u001B[0m: Incomplete or corrupted file detected. The auto file hash does not match the provided value of 893217f2bb855e2983157299931e43ff."
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "tf.random.set_seed(42)\n",
    "base_model = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "tf.random.set_seed(42)\n",
    "base_model = EfficientNetV2B0(input_shape=(32, 32, 3), include_top = False)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-37e9ff19b9154a0b",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "start_time": "2024-03-08T06:46:48.617284Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "tf.random.set_seed(42)\n",
    "base_model_ = EfficientNetV2B0(input_shape=(32, 32, 3), include_top = False)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert base_model.input_shape == base_model_.input_shape\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-babd91ac5195d0cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Loading and Preparing the Data\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "In the code cell below, use the function `load_data()` on `cifar10` to prepare the target variables. Assign the result to `(X_train`, `Y_train), (X_test, Y_test)`.\n",
    "\n",
    "Next, use the function `to_categorical` with argument `Y_train` and assign the result to `Y_train`.\n",
    "\n",
    "Finally, use the function `to_categorical` with argument `Y_test` and assign the result to `Y_test`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-08T06:46:48.618277Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-edd995a41f912de0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "start_time": "2024-03-08T06:46:48.619274Z"
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "(X_train, Y_train), (X_test, Y_test) = ('', ''), ('', '')\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "Y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3d49cd327dbdaebb",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "start_time": "2024-03-08T06:46:48.619274Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "(X_train_, y_train_), (X_test_, y_test_) = cifar10.load_data()\n",
    "Y_train_ = to_categorical(y_train_)\n",
    "Y_test_ = to_categorical(y_test_)#\n",
    "#\n",
    "#\n",
    "np.testing.assert_array_equal(X_train, X_train_)\n",
    "np.testing.assert_array_equal(Y_train, Y_train_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1ec22b2306a3964f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Generating Feature Maps\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "To use the pretrained network, use the `.predict` method with argument equal to `X_train_sample` on `base_model`. Assign the results as `features`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-08T06:46:48.619274Z"
    }
   },
   "outputs": [],
   "source": [
    "#for speeding up the process\n",
    "X_train_sample = X_train[:10]\n",
    "y_train_sample = Y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-87eeaf7fdc839229",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "start_time": "2024-03-08T06:46:48.620271Z"
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "tf.random.set_seed(42)\n",
    "features = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "tf.random.set_seed(42)\n",
    "features = base_model.predict(X_train_sample)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6f3bbabdc1c6604f",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "start_time": "2024-03-08T06:46:48.620271Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "tf.random.set_seed(42)\n",
    "features_ = base_model_.predict(X_train_sample)\n",
    "#\n",
    "#\n",
    "#\n",
    "np.testing.assert_array_equal(features, features_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8de266ae16e5ba0b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Making Predictions for Data\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Below, use the function `Sequential` to create a neural network named `top` using the following architecture:\n",
    "\n",
    "- One `Flatten` layer to flatten the results of pooling\n",
    "- One `Dense` layer with 100 nodes and `relu` activation\n",
    "- One `Dense` output layer 10 noded and with `softmax` activation\n",
    "\n",
    "Compile `top` using `categorical_crossentropy` as your loss and  `accuracy` as your metric.\n",
    "\n",
    "Use the `fit()` function on the `top` network to fit the training data `features` and `Y_train`. Set the argument `validation_split` equal to `0.2`, the argument `epochs` equal to 5, and the argument `verbose` equal to 0.  Assign the result to the variable `history` below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-38a34b347a2ba110",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "start_time": "2024-03-08T06:46:48.620271Z"
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "tf.random.set_seed(42)\n",
    "top = ''\n",
    "history = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "tf.random.set_seed(42)\n",
    "top = Sequential([Flatten(), Dense(100, activation = 'relu'), Dense(10, activation = 'softmax')])\n",
    "\n",
    "top.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = top.fit(features, Y_train, validation_split = 0.2, epochs = 5, verbose = 0)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(history.history['accuracy'][-5:])\n",
    "print(history.history['val_accuracy'][-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c9d614651286b187",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "start_time": "2024-03-08T06:46:48.621267Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "tf.random.set_seed(42)\n",
    "top_ = Sequential([Flatten(), Dense(100, activation = 'relu'),\n",
    "                    Dense(10, activation = 'softmax')])\n",
    "\n",
    "top_.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history_ = top.fit(features_, Y_train_, validation_split = 0.2, \n",
    "                  epochs = 5, verbose = 0)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert len(history.history['accuracy']) == len(history_.history['accuracy'])\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-64ace0d651f2f620",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Predicting Test Data\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "To make predictions, use the function `predict()` on `base_model` with argument `X_test[:10]`. Assign the result to `test_features`.\n",
    "\n",
    "Next, use the function `predict()` on the `top` object with argument equal to `test_features`. Use the function NumPy  function `argmax` to retrieve the indices of the maximum elements in the array along the `axis` 1.\n",
    "Assign the result to the variable `preds`.\n",
    "\n",
    "HINT: The pseudocode for this last step is given below:\n",
    "\n",
    "```Python\n",
    "preds = np.argmax(conv_model.predict(...), axis = ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-976c8b558feb0f91",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "start_time": "2024-03-08T06:46:48.621267Z"
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "tf.random.set_seed(42)\n",
    "test_exs = X_test[:10]\n",
    "test_preds = ''\n",
    "  \n",
    "### BEGIN SOLUTION\n",
    "tf.random.set_seed(42)\n",
    "test_features = base_model.predict(X_test[:10])\n",
    "test_preds = np.argmax(top.predict(test_features), axis = 1)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(test_preds)\n",
    "print(y_test[:10].reshape(10,))\n",
    "fig, ax = plt.subplots(2, 5, figsize = (20, 5))\n",
    "c = 0\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        ax[i, j].imshow(X_test[c])\n",
    "        ax[i, j].set_title(f'Predicted {test_preds[c]}\\nActual {y_test[c][0]}')\n",
    "        c += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e35078fc456c3fed",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "start_time": "2024-03-08T06:46:48.621267Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "tf.random.set_seed(42)\n",
    "test_features_ = base_model.predict(X_test_[:10])\n",
    "test_preds_ = np.argmax(top_.predict(test_features_), axis = 1)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert len(test_preds), len(test_preds_)\n",
    "### END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
