{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Load libraries"
   ],
   "metadata": {
    "id": "_HQIrsWs2ePU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "id": "t5Sr4kdA2dr6",
    "ExecuteTime": {
     "end_time": "2024-03-07T00:04:59.960909Z",
     "start_time": "2024-03-07T00:04:58.018644Z"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set the Device\n",
    "\n",
    "You should determine if a GPU is available and set your device accordingly."
   ],
   "metadata": {
    "id": "2rDp6iki3Kjt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkwgOVTX3IGc",
    "outputId": "b3bb8001-2854-45e3-9b5d-6a24552ed7c6",
    "ExecuteTime": {
     "end_time": "2024-03-07T00:05:00.000622Z",
     "start_time": "2024-03-07T00:04:59.960909Z"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T00:05:00.007036Z",
     "start_time": "2024-03-07T00:05:00.001627Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the Iris dataset"
   ],
   "metadata": {
    "id": "S6Gk5hSc3Ewq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZGXdz8g_1zXE",
    "ExecuteTime": {
     "end_time": "2024-03-07T00:05:00.017354Z",
     "start_time": "2024-03-07T00:05:00.008041Z"
    }
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split the dataset into a training set and a test set"
   ],
   "metadata": {
    "id": "1xhuKVD63Q5r"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "id": "HD4n64bX3NCX",
    "ExecuteTime": {
     "end_time": "2024-03-07T00:05:00.021627Z",
     "start_time": "2024-03-07T00:05:00.018355Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert datasets to PyTorch tensors\n",
    "\n",
    "In PyTorch, the .to(device) method is used to explicitly move tensors or models to a specific device, either the CPU or a GPU. When you're training neural networks, especially deep ones, computational requirements can be high, and utilizing a GPU can significantly speed up the training process."
   ],
   "metadata": {
    "id": "Z5kwalZq3u4l"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X_train = torch.FloatTensor(X_train).to(device)\n",
    "y_train = torch.LongTensor(y_train).to(device)\n",
    "X_test = torch.FloatTensor(X_test).to(device)\n",
    "y_test = torch.LongTensor(y_test).to(device)\n"
   ],
   "metadata": {
    "id": "nKZ6ktZq3T8z",
    "ExecuteTime": {
     "end_time": "2024-03-07T00:05:00.217021Z",
     "start_time": "2024-03-07T00:05:00.022626Z"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define the neural network structure\n",
    "\n",
    "Creating a class is a recommended way to define models in PyTorch. The class-based structure allows for organized, modular, and scalable code. You can create more straightforward models using just functions, but using classes provides greater flexibility, especially for complex architectures.\n",
    "\n",
    "### Notes:\n",
    "- 12 and 8 are somewhat arbitrary numbers. In practice, choosing the number of neurons and layers often involves experimentation.\n",
    "- `nn.Linear` denotes fully connected layers, where each neuron from the previous layer connects to every neuron in the current layer.\n",
    "- ReLU (Rectified Linear Unit) is a popular choice for hidden layers due to its simplicity and effectiveness.\n",
    "- The last layer often doesn't use an activation function because the choice of loss function in the next step (criterion) sometimes includes it.\n",
    "  - For classification tasks with multiple classes, `CrossEntropyLoss` in PyTorch combines a SoftMax activation with a cross-entropy loss."
   ],
   "metadata": {
    "id": "D1Ma89CW4SXo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class IrisNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IrisNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 12)    # First hidden layer with 12 neurons\n",
    "        self.fc2 = nn.Linear(12, 8)   # Second hidden layer with 8 neurons\n",
    "        self.fc3 = nn.Linear(8, 3)    # Output layer with 3 neurons (for the 3 classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # Apply ReLU activation function after first hidden layer\n",
    "        x = torch.relu(self.fc2(x))  # Apply ReLU activation function after second hidden layer\n",
    "        x = self.fc3(x)              # No activation here as we'll use CrossEntropyLoss\n",
    "        return x"
   ],
   "metadata": {
    "id": "kVExpgEK31F0",
    "ExecuteTime": {
     "end_time": "2024-03-07T00:05:00.221216Z",
     "start_time": "2024-03-07T00:05:00.217021Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = IrisNet().to(device)"
   ],
   "metadata": {
    "id": "5wvt4CPj4VaE",
    "ExecuteTime": {
     "end_time": "2024-03-07T00:05:00.225379Z",
     "start_time": "2024-03-07T00:05:00.221216Z"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define loss function and optimizer"
   ],
   "metadata": {
    "id": "CdP7pvT84c1a"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()               # This combines a SoftMax activation and a cross-entropy loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01) # Adam optimizer with learning rate of 0.01"
   ],
   "metadata": {
    "id": "HXKiKuxr4Zyg",
    "ExecuteTime": {
     "end_time": "2024-03-07T00:05:01.255287Z",
     "start_time": "2024-03-07T00:05:00.225379Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training loop"
   ],
   "metadata": {
    "id": "_fSKbFPn4iPw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "best_val_loss = float('inf')  # Start with a very high initial best loss\n",
    "patience = 10  # Define how many epochs to wait without improvement\n",
    "counter = 0  # Initialize counter\n",
    "\n",
    "for epoch in range(500):   # Increased epochs to ensure convergence with raw data\n",
    "    optimizer.zero_grad()  # Clear out the gradients from the last step\n",
    "    out = model(X_train)   # Forward pass: compute predicted y by passing x to the model\n",
    "    loss = criterion(out, y_train) # Compute the loss\n",
    "    loss.backward()        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "    optimizer.step()       # Update model parameters\n",
    "\n",
    "    # Evaluate the model's performance on the validation data\n",
    "    # Ensure no gradients are calculated during this step to save computation and memory\n",
    "    with torch.no_grad():\n",
    "        val_out = model(X_test) # Pass the validation data through the model to get predictions.\n",
    "        val_loss = criterion(val_out, y_test) # Compute the validation loss based on the model's predictions and true labels of validation data.\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0  # Reset the counter since we have observed an improvement in validation loss.\n",
    "    else:\n",
    "        counter += 1  # If validation loss didn't improve, increment the counter.\n",
    "\n",
    "    # If the number of epochs without improvement exceeds our set patience, stop training.\n",
    "    if counter >= patience:\n",
    "        print(\"Early stopping due to no improvement!\")\n",
    "        break  # Exit the training loop\n",
    "\n",
    "    if (epoch+1) % 50 == 0:  # Print the loss every 50 epochs\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pfdz4ZJV4fd6",
    "outputId": "c892c84c-85d5-4da4-c32e-182d14f62e6c",
    "ExecuteTime": {
     "end_time": "2024-03-07T00:05:02.270793Z",
     "start_time": "2024-03-07T00:05:01.256296Z"
    }
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 0.5409395098686218\n",
      "Epoch 100, Loss: 0.08089379221200943\n",
      "Epoch 150, Loss: 0.0559065006673336\n",
      "Epoch 200, Loss: 0.05308171734213829\n",
      "Epoch 250, Loss: 0.05149996280670166\n",
      "Epoch 300, Loss: 0.050328973680734634\n",
      "Epoch 350, Loss: 0.0493655726313591\n",
      "Epoch 400, Loss: 0.04863674193620682\n",
      "Epoch 450, Loss: 0.048053428530693054\n",
      "Epoch 500, Loss: 0.047649189829826355\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate the model"
   ],
   "metadata": {
    "id": "ABu40qRv4lNm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "with torch.no_grad(): # Disable gradient computation during evaluation to save memory and speed up the process\n",
    "    test_out = model(X_test)  # Forward pass: compute predicted outputs by passing test data to the model\n",
    "    _, predicted = torch.max(test_out, 1) # Get the class labels with the highest predicted probabilities\n",
    "    accuracy = accuracy_score(y_test.cpu().numpy(), predicted.cpu().numpy()) # Calculate accuracy by comparing predicted and true labels\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oj-EKXJc4kKw",
    "outputId": "a9ca830b-3d8f-4c6b-aa17-d88e47fe4894",
    "ExecuteTime": {
     "end_time": "2024-03-07T00:05:02.286395Z",
     "start_time": "2024-03-07T00:05:02.271796Z"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 100.00%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deployment\n",
    "For deploying a PyTorch model"
   ],
   "metadata": {
    "id": "C8K_BuxV6EFl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"iris_model.pth\")"
   ],
   "metadata": {
    "id": "GmbkqkR94p0u",
    "ExecuteTime": {
     "end_time": "2024-03-07T00:05:02.291953Z",
     "start_time": "2024-03-07T00:05:02.287395Z"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the model for inference\n",
    "model = IrisNet().to(device)\n",
    "model.load_state_dict(torch.load(\"iris_model.pth\"))\n",
    "model.eval()  # Set the model to evaluation mode"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bUCZMK6N6IKz",
    "outputId": "5fab5ed4-a8f9-42f7-c309-f689ec663718",
    "ExecuteTime": {
     "end_time": "2024-03-07T00:05:02.300573Z",
     "start_time": "2024-03-07T00:05:02.291953Z"
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "IrisNet(\n  (fc1): Linear(in_features=4, out_features=12, bias=True)\n  (fc2): Linear(in_features=12, out_features=8, bias=True)\n  (fc3): Linear(in_features=8, out_features=3, bias=True)\n)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Make a prediction on new data\n",
    "\n",
    "# Suppose you have new data for prediction as a numpy array\n",
    "new_data = [[5.1, 3.5, 1.4, 0.2],  # Some iris measurements\n",
    "            [6.7, 3.0, 5.2, 2.3]]  # Another set of iris measurements\n",
    "\n",
    "# Convert the data to a PyTorch tensor\n",
    "input_tensor = torch.FloatTensor(new_data)\n",
    "\n",
    "# If you used a GPU during training, move the input tensor to the same device\n",
    "if torch.cuda.is_available():\n",
    "    input_tensor = input_tensor.to('cuda')\n",
    "\n",
    "# Get the model's predictions\n",
    "with torch.no_grad():  # This ensures that the operation is not tracked by PyTorch's autograd\n",
    "    outputs = model(input_tensor)\n",
    "\n",
    "# Get the predicted classes\n",
    "_, predicted_classes = torch.max(outputs, 1)\n",
    "\n",
    "# Convert predicted classes to a list\n",
    "predicted_classes = predicted_classes.tolist()\n",
    "\n",
    "print(predicted_classes)  # This will give you the indices of the predicted classes for each input"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_7py85k_6M2S",
    "outputId": "a7174685-eb36-47b1-b364-a5e7925c92d1",
    "ExecuteTime": {
     "end_time": "2024-03-07T00:05:02.316155Z",
     "start_time": "2024-03-07T00:05:02.300573Z"
    }
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO\n",
    "\n",
    "Next time we will learn about hyperparameters in the context of neural networks.\n",
    "\n",
    "Things we will be looking at:\n",
    "- Learning rate\n",
    "- Batch size\n",
    "- Epochs\n",
    "- Optimizer\n",
    "- Network architecture\n",
    "- Dropout\n",
    "- Regularization\n",
    "- Momentum"
   ],
   "metadata": {
    "id": "xCGZqwd69y1V"
   }
  }
 ]
}
