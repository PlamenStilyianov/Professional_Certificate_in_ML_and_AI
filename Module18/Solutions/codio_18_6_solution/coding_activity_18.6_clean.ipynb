{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codio Activity 18.6: Naive Bayes Algorithm\n",
    "\n",
    "**Expected Time = 60 minutes** \n",
    "\n",
    "**Total Points = 35** \n",
    "\n",
    "This activity focuses on the implementation of the Naive Bayes algorithm.  You will use the scikit-learn estimator together with your earlier vectorization strategies to model the WhatsApp text and compare to your earlier work with Logistic Regression.   \n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T23:24:09.086540100Z",
     "start_time": "2024-02-04T23:24:09.066607300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aeee4296207ed403cee0ca6cae8b5c48",
     "grade": false,
     "grade_id": "cell-af402ad5c6fd8123",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Small Example\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "The example below is adapted from Marsland's *Machine Learning an Algorithmic Perspective*.  A small dataset where the features are whether or not a student has a looming deadline, if there is a party going on, and whether or not the student feels lazy.  The activity column is the target, and your aim is to use the naive bayes formula below:\n",
    "\n",
    "$$P(C_i) \\prod_{k} P(X_j^k = a_k | C_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T22:38:31.686147Z",
     "start_time": "2024-02-04T22:38:31.669532700Z"
    }
   },
   "outputs": [],
   "source": [
    "deadline = ['urgent','urgent','near', 'none', 'none', 'none', 'near', 'near', 'near','urgent']\n",
    "party = ['yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no']\n",
    "lazy = ['yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no']\n",
    "activity = ['party', 'study', 'party', 'party', 'pub', 'party', 'study', 'tv', 'party', 'study']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T22:38:31.710066600Z",
     "start_time": "2024-02-04T22:38:31.685149500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  deadline party lazy activity\n0   urgent   yes  yes    party\n1   urgent    no  yes    study\n2     near   yes  yes    party\n3     none   yes   no    party\n4     none    no  yes      pub\n5     none   yes   no    party\n6     near    no   no    study\n7     near    no  yes       tv\n8     near   yes  yes    party\n9   urgent    no   no    study",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>deadline</th>\n      <th>party</th>\n      <th>lazy</th>\n      <th>activity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>urgent</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>party</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>urgent</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>study</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>near</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>party</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>none</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>party</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>none</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>pub</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>none</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>party</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>near</td>\n      <td>no</td>\n      <td>no</td>\n      <td>study</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>near</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>tv</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>near</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>party</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>urgent</td>\n      <td>no</td>\n      <td>no</td>\n      <td>study</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'deadline': deadline, \n",
    "                  'party': party,\n",
    "                  'lazy': lazy,\n",
    "                  'activity': activity})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43c8025b20e400d9b7f3762da6b58c3d",
     "grade": false,
     "grade_id": "cell-5d1437600c3f2ca4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Here, $C_i$ represents the class in the `activity` columm.  Accordingly, if we want to predict a category of activity given the input: \n",
    "\n",
    "```\n",
    "deadline = near\n",
    "party = no\n",
    "lazy = yes\n",
    "```\n",
    "\n",
    "This means we need four probabilities:\n",
    "\n",
    "- $P(party) \\times P(near | party) \\times P(no party | party) \\times P(lazy | party)$\n",
    "- $P(study) \\times P(near | study) \\times p(noparty | study) \\times P(lazy | study)$\n",
    "- $P(pub) \\times P(near | pub) \\times P(noparty | pub) \\times P(lazy | pub)$\n",
    "- $P(tv) \\times P(near | tv) \\times P(noparty | tv) \\times P(lazy |tv)$\n",
    "\n",
    "Compute these four probabilities and assign them to the list `probs` in the order above (party, study, pub, tv). \n",
    "\n",
    "Hint: No need to calculate the probabilities by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "beb789b8a8edc542e8d128cc80a97442",
     "grade": false,
     "grade_id": "cell-9bc8a1669a0b2d75",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-04T22:38:31.718040200Z",
     "start_time": "2024-02-04T22:38:31.702093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.03333333333333333, 0.0, 0.1]\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "probs = []\n",
    "\n",
    "    \n",
    "# YOUR CODE HERE\n",
    "probs = [1/2*2/5*0, 3/10*1/3*1*1/3, 1/10*0, 1/10*1*1*1]\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7075d7966120e0c894e73e7066efab1",
     "grade": true,
     "grade_id": "cell-1654be87992e8f0d",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-04T22:38:31.750938100Z",
     "start_time": "2024-02-04T22:38:31.719036900Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca0bd5a37f6468173dbc3aa2e9218185",
     "grade": false,
     "grade_id": "cell-c2559e0bf33dc6b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### MAP solution\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Using these probabilities, the maximum aposteriori solution involves selecting the outcome that is associated with the highest probability.  Use your list of probabilities to identify the `argmax`.  Note you can use `np.argmax` for this or just inspect the values.  What is the activity associated with the MAP solution?  Assign your answer as a string -- `party`, `study`, `pub`, or `tv` -- to `ans2` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cd5ea67556a9a812a34e0922f4f381e",
     "grade": false,
     "grade_id": "cell-256e274715d26b4a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-04T22:38:31.842334400Z",
     "start_time": "2024-02-04T22:38:31.732990200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tv\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "ans2 = ''\n",
    "\n",
    "    \n",
    "# YOUR CODE HERE\n",
    "ans2 = 'tv'\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(ans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a64377f10dc6a76eef27d9574242cf3",
     "grade": true,
     "grade_id": "cell-d973b12508aa9d50",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-04T22:38:31.844491800Z",
     "start_time": "2024-02-04T22:38:31.747939600Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4cdf93203e31f5052cde0bfdbd4a0f81",
     "grade": false,
     "grade_id": "cell-8e4c25d2e63ea3b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Larger Example\n",
    "\n",
    "Now, you are to use the scikitlearn vectorizers together with the `MultinomialNB` estimator to implement naive bayes algorithm for classifying the WhatsApp data.  The data is loaded and split for you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T22:38:31.845566800Z",
     "start_time": "2024-02-04T22:38:31.763652700Z"
    }
   },
   "outputs": [],
   "source": [
    "happy_df = pd.read_csv('data/Emotion(happy).csv')\n",
    "sad_df = pd.read_csv('data/Emotion(sad).csv.zip', compression = 'zip')\n",
    "full_df = pd.concat([happy_df, sad_df]).reset_index(drop = True)\n",
    "X = full_df.drop('sentiment', axis = 1)\n",
    "y = full_df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['content'], y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57aadebeb9314d3a2064b3c12a8259c6",
     "grade": false,
     "grade_id": "cell-fe75497137cd1f91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Pipeline with `CountVectorizer`\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Below, create a pipeline called `cvect_pipe` with named steps `cvect` and `bayes` that first vectorizes the text and then uses the `MultinomialNB` estimator with all default settings.  Fit this on the train and score it on the test, assigning the accuracy to `cvect_acc` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6799902c2fb9c04e23e8ba5de28d742c",
     "grade": false,
     "grade_id": "cell-6a6f73de4a0f6334",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-04T22:38:31.936770600Z",
     "start_time": "2024-02-04T22:38:31.794549100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'cvect': CountVectorizer(), 'bayes': MultinomialNB()}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "cvect_pipe = ''\n",
    "\n",
    "cvect_acc = ''\n",
    "\n",
    "    \n",
    "# YOUR CODE HERE\n",
    "cvect_pipe = Pipeline([('cvect', CountVectorizer()), ('bayes', MultinomialNB())])\n",
    "cvect_pipe.fit(X_train, y_train)\n",
    "cvect_acc = cvect_pipe.score(X_test, y_test)\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "cvect_pipe.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42fb1f95c083dd104013993324c73271",
     "grade": true,
     "grade_id": "cell-ba6a6fa40eeecdc6",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-04T22:38:31.967173300Z",
     "start_time": "2024-02-04T22:38:31.935774900Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a799b56274c7c97bf3578c47449aaa5",
     "grade": false,
     "grade_id": "cell-58d23432f74f0c60",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Pipeline with `TfidfVectorizer`\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Below, create a pipeline called `tfidf_pipe` with named steps `tfidf` and `bayes` that first vectorizes the text and then uses the `MultinomialNB` estimator with all default settings.  Fit this on the train and score it on the test, assigning the accuracy to `tfidf_acc` below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d177cf5eb6bfaa5b60237f949392473",
     "grade": false,
     "grade_id": "cell-7b58933a2378e7c8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-04T22:38:32.096884100Z",
     "start_time": "2024-02-04T22:38:31.952716300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'tfidf': TfidfVectorizer(), 'bayes': MultinomialNB()}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "tfidf_pipe = ''\n",
    "\n",
    "tfidf_acc = ''\n",
    "\n",
    "    \n",
    "# YOUR CODE HERE\n",
    "tfidf_pipe = Pipeline([('tfidf', TfidfVectorizer()), ('bayes', MultinomialNB())])\n",
    "tfidf_pipe.fit(X_train, y_train)\n",
    "tfidf_acc = tfidf_pipe.score(X_test, y_test)\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "tfidf_pipe.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ad75cb7c1b43a796c3110475339cecd",
     "grade": true,
     "grade_id": "cell-553b4c71d07d6ac5",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-04T22:38:32.107838800Z",
     "start_time": "2024-02-04T22:38:32.092889400Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d4fe6971a94cc69520fef4742273991f",
     "grade": false,
     "grade_id": "cell-317074563a4513fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Assessing performance\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Now, consider searching the hyperparameters of the model.  Specifically, what is the parameter that controls Laplacian smoothing?  Assign your answer as a string to `ans5` below.  As an extra activity, perform a grid search over this parameter and compare the performance to that of `LogisticRegression`.  Also, compare the speed of fit between the logistic and naive bayes models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15b769b2d915fe83b840d61ac8d602af",
     "grade": false,
     "grade_id": "cell-95a20d96bbe59b77",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-04T22:38:32.134748400Z",
     "start_time": "2024-02-04T22:38:32.107838800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "ans5 = ''\n",
    "\n",
    "    \n",
    "# YOUR CODE HERE\n",
    "ans5 = 'alpha'\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(ans5)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pipelines = { 'lr': Pipeline([('tfidf', TfidfVectorizer()), ('lgr', LogisticRegression())]),\n",
    "                'nb': Pipeline([('tfidf', TfidfVectorizer()), ('bayes', MultinomialNB())])\n",
    "              }\n"
   ],
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc19a55512cfdf4c2c081216ff5a9dac",
     "grade": true,
     "grade_id": "cell-17b88d21be4fe45c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-04T23:23:03.436820300Z",
     "start_time": "2024-02-04T23:23:03.412199600Z"
    }
   },
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr with accuracy score 0.776\n",
      "nb with accuracy score 0.721\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    pipeline.fit(X_train, y_train.values.ravel())\n",
    "    score = cross_val_score(pipeline, X_train, y_train.values.ravel(), cv=5, scoring='accuracy').mean()\n",
    "    scores[model_name] = score\n",
    "    print(f\"{model_name} with accuracy score {score:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T23:24:20.845390Z",
     "start_time": "2024-02-04T23:24:19.697563700Z"
    }
   },
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: lr with accuracy score: 0.7755381508300083\n"
     ]
    }
   ],
   "source": [
    "best_model_name = max(scores, key=scores.get)\n",
    "print(f\"Best Model: {best_model_name} with accuracy score: {scores[best_model_name]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T23:25:31.136711400Z",
     "start_time": "2024-02-04T23:25:31.111784200Z"
    }
   },
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "params = {'tfidf__max_features': [100, 500, 1000, 2000],\n",
    "          'tfidf__stop_words': ['english', None],\n",
    "         # 'bayes__alpha': [0.5, 1],\n",
    "          #'lgr__penalty': ['l1', 'l2']\n",
    "          }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T23:35:04.611287100Z",
     "start_time": "2024-02-04T23:35:04.592341700Z"
    }
   },
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tfidf__max_features': 500, 'tfidf__stop_words': 'english'}\n",
      "{'tfidf__max_features': 500, 'tfidf__stop_words': None}\n"
     ]
    }
   ],
   "source": [
    "for pipeline in list(pipelines.values()):\n",
    "    grid = GridSearchCV(pipeline, param_grid=params)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T23:35:12.531508600Z",
     "start_time": "2024-02-04T23:35:05.363408700Z"
    }
   },
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[Pipeline(steps=[('tfidf', TfidfVectorizer()), ('lgr', LogisticRegression())]),\n Pipeline(steps=[('tfidf', TfidfVectorizer()), ('bayes', MultinomialNB())])]"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pipelines.values())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T23:31:37.539616600Z",
     "start_time": "2024-02-04T23:31:37.516684200Z"
    }
   },
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
