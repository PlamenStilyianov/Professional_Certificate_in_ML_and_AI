{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "984f8e1592d945984272a3b8f0fe7f7e",
     "grade": false,
     "grade_id": "cell-b11254d1a270988e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Codio Activity 18.4: Bag of Words: Count Vectorization\n",
    "\n",
    "**Expected Time = 60 minutes**\n",
    "\n",
    "**Total Points = 25**\n",
    "\n",
    "In this activity you will use the scikit-learn vectorization tool `CountVectorizer` to create a bag of words representation of text in a DataFrame.  You will explore how different parameter settings affect the performance of a `LogisticRegression` estimator on a binary classification problem.\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T00:22:14.661119700Z",
     "start_time": "2024-02-06T00:22:14.537462600Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fec13090b5f3425a619c337fea6a3d09",
     "grade": false,
     "grade_id": "cell-580b2c525505e59a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "Below, the data from kaggle is again loaded.  Now, we join the \"sad\" and \"happy\" sentiments which will form the target of our classification models.  The data is also split and named appropriately below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T00:22:14.692556200Z",
     "start_time": "2024-02-06T00:22:14.662267800Z"
    }
   },
   "outputs": [],
   "source": [
    "happy_df = pd.read_csv('data/Emotion(happy).csv')\n",
    "sad_df = pd.read_csv('data/Emotion(sad).csv.zip', compression = 'zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T00:22:14.707393300Z",
     "start_time": "2024-02-06T00:22:14.693507Z"
    }
   },
   "outputs": [],
   "source": [
    "full_df = pd.concat([happy_df, sad_df]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T00:22:14.723517800Z",
     "start_time": "2024-02-06T00:22:14.708402400Z"
    }
   },
   "outputs": [],
   "source": [
    "X = full_df.drop('sentiment', axis = 1)\n",
    "y = full_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T00:22:14.739173900Z",
     "start_time": "2024-02-06T00:22:14.724975700Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X['content'], y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T00:22:14.757580100Z",
     "start_time": "2024-02-06T00:22:14.740170900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1287    ['You Hurt Me But I Still Love You.', 'True Lo...\n1112    Sorry isn’t always enough. Sometimes you actua...\n823     Sometimes two people have to fall apart to rea...\n651     True love isn’t love at first sight but love a...\n1101    i am scared of getting too close to anyone bec...\nName: content, dtype: object"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b0f3d10df8766ebd65ffc73072f404d",
     "grade": false,
     "grade_id": "cell-1af9c3aaf69f904f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Using the `CountVectorizer`\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "To create a bag of words representation of your text data, create an instance of the `CountVectorizer` as `cvect` below.  Leave all the default settings, and assign the transformed version of the text to `dtm`.  Note that because the vectorizer will return a `scipy.sparse` array, to view the contents of the resulting document term matrix the `toarray()` function is used together with the `.get_feature_names()` function to retrieve the fitted vocabulary.\n",
    "\n",
    "Hint: Make sure to transform X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf6c9720d2a66f85206ba601dc28737f",
     "grade": false,
     "grade_id": "cell-993194297edf95fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-06T00:22:14.865164600Z",
     "start_time": "2024-02-06T00:22:14.784275500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   0_0  100  123whatsappstatus  204  30  404  44  45  55  805  ...  yes  \\\n0    0    0                  0    0   0    0   0   0   0    0  ...    2   \n1    0    0                  0    0   0    0   0   0   0    0  ...    0   \n2    0    0                  0    0   0    0   0   0   0    0  ...    0   \n3    0    0                  0    0   0    0   0   0   0    0  ...    0   \n4    0    0                  0    0   0    0   0   0   0    0  ...    0   \n\n   yesterday  yet  you  young  your  yours  yourself  yous  yuh  \n0          0    1  112      0    13      0         2     0    0  \n1          0    0    1      0     0      0         0     0    0  \n2          0    0    0      0     0      0         0     0    0  \n3          0    0    0      0     0      0         0     0    0  \n4          0    0    0      0     0      0         0     0    0  \n\n[5 rows x 1832 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0_0</th>\n      <th>100</th>\n      <th>123whatsappstatus</th>\n      <th>204</th>\n      <th>30</th>\n      <th>404</th>\n      <th>44</th>\n      <th>45</th>\n      <th>55</th>\n      <th>805</th>\n      <th>...</th>\n      <th>yes</th>\n      <th>yesterday</th>\n      <th>yet</th>\n      <th>you</th>\n      <th>young</th>\n      <th>your</th>\n      <th>yours</th>\n      <th>yourself</th>\n      <th>yous</th>\n      <th>yuh</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112</td>\n      <td>0</td>\n      <td>13</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1832 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "cvect = ''\n",
    "dtm = ''\n",
    "\n",
    "    \n",
    "# YOUR CODE HERE\n",
    "cvect = CountVectorizer()\n",
    "dtm = cvect.fit_transform(X_train)\n",
    "\n",
    "### ANSWER CHECK\n",
    "pd.DataFrame(dtm.toarray(), columns = cvect.get_feature_names_out()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "629b418305461e1aba62fe3e311b4c36",
     "grade": true,
     "grade_id": "cell-c04bf752bca2c8b0",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-06T00:22:14.889400100Z",
     "start_time": "2024-02-06T00:22:14.866222600Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d5026f6c711382b93c3023225221aa87",
     "grade": false,
     "grade_id": "cell-748f6d75238662a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Problem 2\n",
    "\n",
    "#### Limiting words with the `CountVectorizer`\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Now, to remove stopwords from the text before vectorizing create a new instance of the `CountVectorizer` and set `stop_words = 'english'` to remove the english language stop words using the same list as in our earlier assignment.  Fit and transform the training data and transform the test data as `X_train_vect_2` and `X_test_vect_2` below.\n",
    "\n",
    "Hint: Use `fit_transform` for the training data, and `transform` for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e7a176a89a462c375166de7afe0567f",
     "grade": false,
     "grade_id": "cell-3774a2265d6e5e27",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-06T00:22:15.005486800Z",
     "start_time": "2024-02-06T00:22:14.882331500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<1007x1622 sparse matrix of type '<class 'numpy.int64'>'\n\twith 41589 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "cvect2 = ''\n",
    "X_train_vect_2 = ''\n",
    "X_test_vect_2 = ''\n",
    "    \n",
    "# YOUR CODE HERE\n",
    "cvect2 = CountVectorizer(stop_words = 'english')\n",
    "X_train_vect_2 = cvect2.fit_transform(X_train)\n",
    "X_test_vect_2 = cvect2.transform(X_test)\n",
    "\n",
    "### ANSWER CHECK\n",
    "X_train_vect_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8caad377dc67de4f76fcf0c3a00ed6ec",
     "grade": true,
     "grade_id": "cell-e51bed3fb28e4961",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-06T00:22:15.021675500Z",
     "start_time": "2024-02-06T00:22:15.006604400Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "caa80ba9e40f64102b66d819eac99763",
     "grade": false,
     "grade_id": "cell-08908731ede92487",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Problem 3\n",
    "\n",
    "#### Limiting words with stopwords and higher counts\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Now, remove stopwords using `stop_words = 'english'` and limit the features to the top 300 words based on counts using the `max_features` argument.  Fit and transform your data appropriately as `X_train_vect_3` and `X_test_vect_3` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71d81b27ffc8e89a34b16cfa48c2f805",
     "grade": false,
     "grade_id": "cell-fc155b6ae942f747",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-06T00:22:15.145998800Z",
     "start_time": "2024-02-06T00:22:15.021675500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<1007x300 sparse matrix of type '<class 'numpy.int64'>'\n\twith 33225 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "cvect3 = ''\n",
    "X_train_vect_3 = ''\n",
    "X_test_vect_3 = ''\n",
    "    \n",
    "# YOUR CODE HERE\n",
    "cvect3 = CountVectorizer(stop_words = 'english', max_features = 300)\n",
    "X_train_vect_3 = cvect3.fit_transform(X_train)\n",
    "X_test_vect_3 = cvect3.transform(X_test)\n",
    "\n",
    "### ANSWER CHECK\n",
    "X_train_vect_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e37eb317fc6df865236fe5f83af4310",
     "grade": true,
     "grade_id": "cell-b1e8621d879a2aa7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-06T00:22:15.172481300Z",
     "start_time": "2024-02-06T00:22:15.145998800Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d531667d77e87b58f7603c5d77c0de16",
     "grade": false,
     "grade_id": "cell-52dbe3ec03ade066",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Using the text with `LogisticRegression`\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Create a `Pipeline` object named `vect_pipe_1` below that has steps named `cvect` and `lgr`, using both a default `CountVectorizer` transformer and `LogisticRegression` estimator. Fit this on the training data and evaluate it on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2b1d5888129599771a348635820333c",
     "grade": false,
     "grade_id": "cell-0ced72c8a300928f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-06T00:22:15.318754300Z",
     "start_time": "2024-02-06T00:22:15.163151600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'cvect': CountVectorizer(), 'lgr': LogisticRegression()}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "vect_pipe_1 = ''\n",
    "\n",
    "test_acc = ''\n",
    "\n",
    "    \n",
    "# YOUR CODE HERE\n",
    "vect_pipe_1 = Pipeline([('cvect', CountVectorizer()), ('lgr', LogisticRegression())])\n",
    "vect_pipe_1.fit(X_train, y_train)\n",
    "test_acc = vect_pipe_1.score(X_test, y_test)\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "vect_pipe_1.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a42556c5f85b26a79eaabdf632cdc0b1",
     "grade": true,
     "grade_id": "cell-153fc31becfdf95e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-06T00:22:15.354596600Z",
     "start_time": "2024-02-06T00:22:15.318754300Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba830e8717691f6547bd71b9c9c88081",
     "grade": false,
     "grade_id": "cell-67c7fd85b923ac68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Pipeline and Grid Search\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Finally, to abstract this work into a single step you can create a `Pipeline` with named steps `cvect` and `lgr` below that vectorize and model the data.  Then, use the parameter grid to perform a grid search for the ideal parameters to represent the text and build a classification model. \n",
    "\n",
    "Hint: Use vect_pipe_1 from problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T00:22:15.355607200Z",
     "start_time": "2024-02-06T00:22:15.334026600Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {'cvect__max_features': [100, 500, 1000, 2000],\n",
    "         'cvect__stop_words': ['english', None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5c26d73d370648dd664d3dfddabdac9",
     "grade": false,
     "grade_id": "cell-e57872e309a8659f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-06T00:25:34.019408100Z",
     "start_time": "2024-02-06T00:22:35.981239500Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# YOUR CODE HERE\u001B[39;00m\n\u001B[0;32m      7\u001B[0m grid \u001B[38;5;241m=\u001B[39m GridSearchCV(vect_pipe_1, param_grid\u001B[38;5;241m=\u001B[39mparams)\n\u001B[1;32m----> 8\u001B[0m \u001B[43mgrid\u001B[49m\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[0;32m      9\u001B[0m test_acc \u001B[38;5;241m=\u001B[39m grid\u001B[38;5;241m.\u001B[39mscore(X_test, y_test)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m### ANSWER CHECK\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[13], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# YOUR CODE HERE\u001B[39;00m\n\u001B[0;32m      7\u001B[0m grid \u001B[38;5;241m=\u001B[39m GridSearchCV(vect_pipe_1, param_grid\u001B[38;5;241m=\u001B[39mparams)\n\u001B[1;32m----> 8\u001B[0m \u001B[43mgrid\u001B[49m\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[0;32m      9\u001B[0m test_acc \u001B[38;5;241m=\u001B[39m grid\u001B[38;5;241m.\u001B[39mscore(X_test, y_test)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m### ANSWER CHECK\u001B[39;00m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:937\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:928\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:585\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\Java\\JetBrains\\DataSpell_2023.2.1\\plugins\\python-ce\\helpers\\pydev\\pydevd.py:1184\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1181\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1183\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1184\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Java\\JetBrains\\DataSpell_2023.2.1\\plugins\\python-ce\\helpers\\pydev\\pydevd.py:1199\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1196\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1198\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1199\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1201\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1203\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "grid = ''\n",
    "test_acc = ''\n",
    "\n",
    "    \n",
    "# YOUR CODE HERE\n",
    "grid = GridSearchCV(vect_pipe_1, param_grid=params)\n",
    "grid.fit(X_train, y_train)\n",
    "test_acc = grid.score(X_test, y_test)\n",
    "\n",
    "### ANSWER CHECK\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a6254865e16e976411d8a40535cca48",
     "grade": true,
     "grade_id": "cell-9b5e5e18bd2bee37",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-06T00:26:27.645717100Z",
     "start_time": "2024-02-06T00:26:27.634755100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(1007,)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(1343, 1)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T00:26:47.098109300Z",
     "start_time": "2024-02-06T00:26:47.068209500Z"
    }
   },
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
