{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classifiers\n",
    "\n",
    "This activity focuses on using the `BaggingClassifier`.  You will use the scikitlearn implementation to compare performance on the fetal health dataset to that of the other models in the module -- Random Forests, Adaptive Boosting, and Gradient Boosting. The `BaggingClassifier` is a meta estimator that will aggregate estimators built on samples of the data.  You are to specify certain estimators and samples to become familiar with the functionality of the estimator and the variations you can produce with important arguments.  \n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T19:19:41.981105100Z",
     "start_time": "2024-02-27T19:19:40.994519400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Plamen\\AppData\\Local\\Temp\\ipykernel_25044\\1005376950.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and Documentation\n",
    "\n",
    "Below the data is loaded and prepared.  For this exercise, you will be expected to consult the documentation on the `BaggingClassifier` [here](https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator).  The vocabulary in each problem can be found in the documentation and you are expected to use the correct settings for the arguments as a result of reading the documentation.  For each model, be sure to set `random_state = 42`.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T19:19:41.995034200Z",
     "start_time": "2024-02-27T19:19:41.983114Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/fetal.zip', compression = 'zip')\n",
    "X, y = df.drop('fetal_health', axis = 1), df['fetal_health']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Aggregating bootstrap models\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "To start, create an ensemble of `DecisionTreeClassifier` classifiers built on bootstrap samples of the data. Remember to set the `random_state = 42`.  *This is equivalent to the default model for `BaggingClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T19:23:44.379777700Z",
     "start_time": "2024-02-27T19:23:44.294943900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9511278195488722\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "bagged_model = ''\n",
    "bagged_score = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "bagged_model = BaggingClassifier(random_state=42).fit(X_train, y_train)\n",
    "bagged_score = bagged_model.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(bagged_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T19:23:45.080551800Z",
     "start_time": "2024-02-27T19:23:44.984270900Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "bagged_model_ = BaggingClassifier(random_state=42).fit(X_train, y_train)\n",
    "bagged_score_ = bagged_model_.score(X_test, y_test)\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "assert bagged_score == bagged_score_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Pasting vs. Bagging\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Consult the documentation [here](https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator) and adjust the appropriate argument to change from **bagging** to **pasting**.  Create your model as `pasted_model` and score on the test data as `pasted_score`.  Be sure to set `random_state = 42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T19:26:39.470344100Z",
     "start_time": "2024-02-27T19:26:39.362538400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9379699248120301\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "pasted_model = ''\n",
    "pasted_score = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "pasted_model = BaggingClassifier(random_state=42, bootstrap=False).fit(X_train, y_train)\n",
    "pasted_score = pasted_model.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(pasted_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T19:26:40.514353Z",
     "start_time": "2024-02-27T19:26:40.411986300Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "pasted_model_ = BaggingClassifier(random_state=42, bootstrap=False).fit(X_train, y_train)\n",
    "pasted_score_ = pasted_model_.score(X_test, y_test)\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "assert pasted_score == pasted_score_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Random Subspaces\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Consult the documentation [here](https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator) and adjust the appropriate argument to change from **bagging** to **random subspaces** with at most 10 features sampled.  Train this on the training data and score it on the test data. Create your model as `random_subspace` and score as `subspace_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T19:28:02.257706300Z",
     "start_time": "2024-02-27T19:28:02.195180200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.943609022556391\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "subspace_model = ''\n",
    "subspace_score = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "subspace_model = BaggingClassifier(random_state=42, bootstrap=False, max_features=10).fit(X_train, y_train)\n",
    "subspace_score = subspace_model.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(subspace_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T19:28:02.653733Z",
     "start_time": "2024-02-27T19:28:02.590303400Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "subspace_model_ = BaggingClassifier(random_state=42, bootstrap=False, max_features=10).fit(X_train, y_train)\n",
    "subspace_score_ = subspace_model_.score(X_test, y_test)\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "assert subspace_score == subspace_score_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Random Patches\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Consult the documentation [here](https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator) and adjust the appropriate argument to change from **bagging** to **random patches**. Use no more than 30% of the data and no more than 10 features in your samples.  Train this on the training data and score it on the test data as `patches_model` and `patches_score` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T19:28:04.504326600Z",
     "start_time": "2024-02-27T19:28:04.460114400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9304511278195489\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "patches_model = ''\n",
    "patches_score = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "patches_model = BaggingClassifier(random_state=42, bootstrap=False, max_features=10, max_samples=0.3).fit(X_train, y_train)\n",
    "patches_score = patches_model.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(patches_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T19:28:05.839223200Z",
     "start_time": "2024-02-27T19:28:05.806574600Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "patches_model_ = BaggingClassifier(random_state=42, bootstrap=False, max_features=10, max_samples=0.3).fit(X_train, y_train)\n",
    "patches_score_ = patches_model_.score(X_test, y_test)\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "assert patches_score == patches_score_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Nature of the Tree Models\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Consult the documentation [here](https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator) and observe whether or not bagging typically works with simple or complex tree models.  Enter your answer as `simple` or `complex` as a string to `ans5`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T19:19:42.559746Z",
     "start_time": "2024-02-27T19:19:42.554471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complex\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "ans5 = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "ans5 = 'complex'\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(ans5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T19:19:42.560770400Z",
     "start_time": "2024-02-27T19:19:42.559243100Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "ans5_ = 'complex'\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "assert ans5 == ans5_\n",
    "### END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
