{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-461a2bb27ab444fe",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Codio Activity 12.4: Accuracy, Precision, and Recall\n",
    "\n",
    "**Expected Time: 60 Minutes**\n",
    "\n",
    "**Total Points: 55**\n",
    "\n",
    "This activity focuses on differentiating between three classification metrics -- accuracy, precision, and recall.  Depending on the situation you may have different perspectives.  In this assignment, you will use the scikit-learn metrics to evaluate and compare performance metrics.  In the next assignment, you will use confusion matrices to visually intuit these ideas.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d992c68668ebdd29",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Index\n",
    "\n",
    "- [Problem 1](#Problem-1)\n",
    "- [Problem 2](#Problem-2)\n",
    "- [Problem 3](#Problem-3)\n",
    "- [Problem 4](#Problem-4)\n",
    "- [Problem 5](#Problem-5)\n",
    "- [Problem 6](#Problem-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T14:00:53.873417200Z",
     "start_time": "2023-12-01T14:00:52.892416800Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a2e3e4ca7dc600d6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "Your dataset for this problem will be a built in dataset from scikitlearn containing measurements determined from images of breast cancer tumors and the label of malignant or benign.  There are 30 features and the target feature.  The data is loaded and split below.  \n",
    "<p>Target = 0 means the cancer is malignant, Target = 1 means the cancer is benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T14:00:53.904129700Z",
     "start_time": "2023-12-01T14:00:53.872418800Z"
    }
   },
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T14:00:53.918018100Z",
     "start_time": "2023-12-01T14:00:53.903133Z"
    }
   },
   "outputs": [],
   "source": [
    "df = cancer.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T14:00:53.998538600Z",
     "start_time": "2023-12-01T14:00:53.921541600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n0        17.99         10.38          122.80     1001.0          0.11840   \n1        20.57         17.77          132.90     1326.0          0.08474   \n2        19.69         21.25          130.00     1203.0          0.10960   \n3        11.42         20.38           77.58      386.1          0.14250   \n4        20.29         14.34          135.10     1297.0          0.10030   \n\n   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n0           0.27760          0.3001              0.14710         0.2419   \n1           0.07864          0.0869              0.07017         0.1812   \n2           0.15990          0.1974              0.12790         0.2069   \n3           0.28390          0.2414              0.10520         0.2597   \n4           0.13280          0.1980              0.10430         0.1809   \n\n   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n0                 0.07871  ...          17.33           184.60      2019.0   \n1                 0.05667  ...          23.41           158.80      1956.0   \n2                 0.05999  ...          25.53           152.50      1709.0   \n3                 0.09744  ...          26.50            98.87       567.7   \n4                 0.05883  ...          16.67           152.20      1575.0   \n\n   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n0            0.1622             0.6656           0.7119                0.2654   \n1            0.1238             0.1866           0.2416                0.1860   \n2            0.1444             0.4245           0.4504                0.2430   \n3            0.2098             0.8663           0.6869                0.2575   \n4            0.1374             0.2050           0.4000                0.1625   \n\n   worst symmetry  worst fractal dimension  target  \n0          0.4601                  0.11890       0  \n1          0.2750                  0.08902       0  \n2          0.3613                  0.08758       0  \n3          0.6638                  0.17300       0  \n4          0.2364                  0.07678       0  \n\n[5 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean radius</th>\n      <th>mean texture</th>\n      <th>mean perimeter</th>\n      <th>mean area</th>\n      <th>mean smoothness</th>\n      <th>mean compactness</th>\n      <th>mean concavity</th>\n      <th>mean concave points</th>\n      <th>mean symmetry</th>\n      <th>mean fractal dimension</th>\n      <th>...</th>\n      <th>worst texture</th>\n      <th>worst perimeter</th>\n      <th>worst area</th>\n      <th>worst smoothness</th>\n      <th>worst compactness</th>\n      <th>worst concavity</th>\n      <th>worst concave points</th>\n      <th>worst symmetry</th>\n      <th>worst fractal dimension</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>0.07871</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>0.05667</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>0.05999</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>0.09744</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>0.05883</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T14:00:54.033850700Z",
     "start_time": "2023-12-01T14:00:53.998538600Z"
    }
   },
   "outputs": [],
   "source": [
    "df['target'] = np.where(df['target'] == 0, 'malignant', 'benign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T14:00:54.212099800Z",
     "start_time": "2023-12-01T14:00:54.018582500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=df, x = 'target')\n",
    "plt.title('Count of target observations');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T14:00:54.277369400Z",
     "start_time": "2023-12-01T14:00:54.214487400Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis = 1), df.target, random_state = 42, stratify = df.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2863deba924ec181",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Setting a Baseline\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "It is always important to get in the habit of checking the baseline score for a classification model.  Here, when splitting the data the `stratify` argument was used so that both the train and test set would have a similar proportion of classes.  This can be seen below.  Using this data, what is a baseline score for the model that predicts the majority class for all data points?  Enter your answer as a string to `baseline` below.\n",
    "\n",
    "```\n",
    "a) 37% accuracy\n",
    "b) 63% accuracy\n",
    "c) 50% accuracy\n",
    "d) 100% accuracy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T14:00:54.279638800Z",
     "start_time": "2023-12-01T14:00:54.231656300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "benign       0.629371\nmalignant    0.370629\nName: target, dtype: float64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T14:00:54.280671600Z",
     "start_time": "2023-12-01T14:00:54.245491400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "benign       0.626761\nmalignant    0.373239\nName: target, dtype: float64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba104599bdcf75e3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-01T14:00:54.281680700Z",
     "start_time": "2023-12-01T14:00:54.261690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "baseline = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "baseline = 'b'\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6f1dde03b01d6a73",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2023-12-01T14:00:54.298731100Z",
     "start_time": "2023-12-01T14:00:54.276371800Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "baseline_ = 'b'\n",
    "#\n",
    "#\n",
    "#\n",
    "assert type(baseline) == type(baseline_)\n",
    "assert baseline == baseline_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c9409d89e41b7239",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Pipeline for scaling and KNN\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "To begin, create a pipeline `knn_pipe` with named steps `scale` and `knn` that uses the `StandardScaler` followed by the `KNeighborsClassifier` with `n_neighbors = 10`.  Fit this on the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bf877edbb803110f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-01T14:00:54.352849500Z",
     "start_time": "2023-12-01T14:00:54.292059900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('scale', StandardScaler()),\n                ('knn', KNeighborsClassifier(n_neighbors=10))])",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scale&#x27;, StandardScaler()),\n                (&#x27;knn&#x27;, KNeighborsClassifier(n_neighbors=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scale&#x27;, StandardScaler()),\n                (&#x27;knn&#x27;, KNeighborsClassifier(n_neighbors=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=10)</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "knn_pipe = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "knn_pipe = Pipeline([('scale', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors = 10))])\n",
    "knn_pipe.fit(X_train, y_train)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "knn_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-01ce2c183e373859",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2023-12-01T14:00:54.354842700Z",
     "start_time": "2023-12-01T14:00:54.309547700Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "knn_pipe_ = Pipeline([('scale', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors = 10))])\n",
    "knn_pipe_.fit(X_train, y_train)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert list(knn_pipe_.named_steps.keys()) == list(knn_pipe.named_steps.keys()), 'Make sure you have steps named scale and knn'\n",
    "assert knn_pipe_.named_steps['knn'].n_neighbors == knn_pipe.named_steps['knn'].n_neighbors\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9da9732e2dda42cc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Evaluating your classifier\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Three scoring methods have been imported from scikit-learn that are used by comparing predictions to actual values.  Choose which method from `precision_score`, `recall_score`, and `accuracy_score` indicate fewer false positives (where a higher score means FEWER false positives). Use this scoring method to score `knn_pipe` on the test data as `min_fp` below.\n",
    "\n",
    "**NOTE**: You will need to pass `pos_label = 'malignant'` here to make the scorer aware of which label is the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d0197b85df2cb969",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-01T14:00:54.402790Z",
     "start_time": "2023-12-01T14:00:54.324905600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9795918367346939\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "min_fp = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "knn_pipe = Pipeline([('scale', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors = 10))])\n",
    "knn_pipe.fit(X_train, y_train)\n",
    "min_fp = precision_score(y_test, knn_pipe.predict(X_test), pos_label = 'malignant')\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(min_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d94f6ef9105a0ceb",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2023-12-01T14:00:54.404160800Z",
     "start_time": "2023-12-01T14:00:54.385660800Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "knn_pipe_ = Pipeline([('scale', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors = 10))])\n",
    "knn_pipe_.fit(X_train, y_train)\n",
    "min_fp_ = precision_score(y_test, knn_pipe_.predict(X_test), pos_label = 'malignant')\n",
    "#\n",
    "#\n",
    "#\n",
    "assert min_fp_ == min_fp, 'Check the formulas from video for denominator containing false positive.'\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1ad92eeae259341d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Right kind of mistakes\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "In this situation, which mistake is more detrimental to the patient if we attempt to use our algorithm to classify tumors as malignant or benign.  Would you rather avoid false positives or false negatives?  What metric does this mean we should use here? Enter your answer as a string to `best_metric` below -- `precision`, `recall`, or `accuracy`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6aaa8fe81bbb4d7b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-01T14:00:54.422668200Z",
     "start_time": "2023-12-01T14:00:54.400483900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "best_metric = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "best_metric = 'recall'\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(best_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4b51f19267f93b23",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2023-12-01T14:00:54.476907300Z",
     "start_time": "2023-12-01T14:00:54.420647700Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "best_metric_ = 'recall'\n",
    "#\n",
    "#\n",
    "#\n",
    "assert best_metric == best_metric_, 'False negatives would perhaps be the worst here.'\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c1a2df0d0ad78b4f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Improving a model based on specific metric\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Before, when using the `GridSearchCV` the best model has been selected using the default scoring method of the estimator.  You can change this behavior by passing an appropriate metric to the `scoring` argument. \n",
    "\n",
    "Before doing so, to make things easier you should set the target features to numeric datatypes.  Use the given dictionary to map the numeric values to `y_train` and `y_test` as `y_train_numeric` and `y_test_numeric` accordingly.  Then, implement a grid search called `recall_grid` for odd numbers of neighbors from 1 to 21 where `recall` is the scoring metric used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T14:00:54.479996200Z",
     "start_time": "2023-12-01T14:00:54.433444700Z"
    }
   },
   "outputs": [],
   "source": [
    "target_map = {'malignant': 1, 'benign': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-56518a7f6dcaede8",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-01T14:25:48.015226900Z",
     "start_time": "2023-12-01T14:25:47.661822900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best recall score is:  0.89\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "y_train_numeric = ''\n",
    "y_test_numeric = ''\n",
    "recall_grid = ''\n",
    "\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "y_train_numeric = y_train.map(target_map)\n",
    "y_test_numeric = y_test.map(target_map)\n",
    "recall_grid = GridSearchCV(knn_pipe, param_grid = {'knn__n_neighbors': range(1, 23, 2)}, scoring = 'recall')\n",
    "recall_grid.fit(X_train, y_train_numeric)\n",
    "best_score = recall_grid.score(X_test, y_test_numeric)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(f'The best recall score is: {best_score: .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b5b6856b3af366e8",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2023-12-01T14:25:49.679808100Z",
     "start_time": "2023-12-01T14:25:49.324989700Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "y_train_numeric_ = y_train.map(target_map)\n",
    "y_test_numeric_ = y_test.map(target_map)\n",
    "recall_grid_ = GridSearchCV(knn_pipe_, param_grid = {'knn__n_neighbors': range(1, 23, 2)}, scoring = 'recall')\n",
    "recall_grid_.fit(X_train, y_train_numeric_)\n",
    "best_score_ = recall_grid_.score(X_test, y_test_numeric_)\n",
    "#\n",
    "#\n",
    "#\n",
    "#np.testing.assert_array_equal(y_train_numeric, y_train_numeric_)\n",
    "assert best_score_ == best_score, 'Make sure you use scoring = \"recall\".'\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bb3e3fa1772b3d20",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 6\n",
    "\n",
    "#### Verifying the score\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Use your `recall_grid` to make predictions on the test data and assign to preds.  Use these predictions to count the number of false negatives and true positives.  Assign these as integers to `fp` and `tp` respectively below.  This should show that the grid search scoring method has been changed to recall.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-91cd2d980bd4520d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-01T14:25:51.882591900Z",
     "start_time": "2023-12-01T14:25:51.860627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall by hand is:  0.89\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "recall_preds = ''\n",
    "fp = ''\n",
    "tp = ''\n",
    "\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "recall_preds = recall_grid.predict(X_test)\n",
    "fn = 0\n",
    "tp = 0\n",
    "for i,j in zip(recall_preds, y_test_numeric):\n",
    "    if i == 0 and j == 1:\n",
    "        fn += 1\n",
    "    if i == 1 and j == 1:\n",
    "        tp += 1\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(f'Recall by hand is: {tp/(tp + fn): .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d89adeb19e08a168",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2023-12-01T14:25:53.598580500Z",
     "start_time": "2023-12-01T14:25:53.583367800Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "recall_preds_ = recall_grid_.predict(X_test)\n",
    "fn_ = 0\n",
    "tp_ = 0\n",
    "for i,j in zip(recall_preds_, y_test_numeric_):\n",
    "    if i == 0 and j == 1:\n",
    "        fn_ += 1\n",
    "    if i == 1 and j == 1:\n",
    "        tp_ += 1\n",
    "#\n",
    "#\n",
    "#\n",
    "assert fn == fn_ \n",
    "assert tp == tp_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a8162c9f910462ea",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "In other situations, a different metric may make sense.  Here, a specific kind of error -- labeling a cancerous tumor as not so -- is something we certainly want to avoid.  In the next activity, you will continue to consider these issues using confusion matrices to unpack the errors and how changing parameters of the estimator effects this."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
