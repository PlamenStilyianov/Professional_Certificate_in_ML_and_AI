{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "X8h-IQP1GNkX",
    "ExecuteTime": {
     "end_time": "2023-11-02T19:41:25.925549100Z",
     "start_time": "2023-11-02T19:41:25.421244700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 1: Load the data\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ],
   "metadata": {
    "id": "mzNpEXXCGTga",
    "ExecuteTime": {
     "end_time": "2023-11-02T19:41:25.941737900Z",
     "start_time": "2023-11-02T19:41:25.927698300Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 2: Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "id": "ru9wg7VNGUtu",
    "ExecuteTime": {
     "end_time": "2023-11-02T19:41:25.970799500Z",
     "start_time": "2023-11-02T19:41:25.942739200Z"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 3: Define a pipeline with data preprocessing and the model\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Data scaling\n",
    "    ('clf', LogisticRegression(solver='liblinear'))  # Logistic regression\n",
    "])"
   ],
   "metadata": {
    "id": "MsvIVqstGWNm",
    "ExecuteTime": {
     "end_time": "2023-11-02T19:41:25.983738700Z",
     "start_time": "2023-11-02T19:41:25.958738900Z"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "len(np.logspace(-4, 4, 20)) # 40 candidates in total, 20 from C and 2 from penalty."
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wspJAvnGGnhJ",
    "outputId": "6b41f390-1144-4c2b-bc0d-5171baaafcd7",
    "ExecuteTime": {
     "end_time": "2023-11-02T19:41:25.996483900Z",
     "start_time": "2023-11-02T19:41:25.973833600Z"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "20"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 4: Define a grid of hyperparameters for tuning\n",
    "param_grid = {\n",
    "    'clf__C': np.logspace(-4, 4, 20),  # Regularization strength\n",
    "    'clf__penalty': ['l1', 'l2']  # Norm used in the penalization\n",
    "}"
   ],
   "metadata": {
    "id": "ObtJ1PWXGYLb",
    "ExecuteTime": {
     "end_time": "2023-11-02T19:41:26.033403900Z",
     "start_time": "2023-11-02T19:41:25.989384100Z"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 5: Create a GridSearchCV object to find the best parameters\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=1, scoring='accuracy')\n",
    "# Verbose=1 will print out the progress"
   ],
   "metadata": {
    "id": "WXUkBUcpGboJ",
    "ExecuteTime": {
     "end_time": "2023-11-02T19:41:26.046373300Z",
     "start_time": "2023-11-02T19:41:26.003523400Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 6: Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train, y_train)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "Pr3T9ILbGdE0",
    "outputId": "88059e4a-4dd0-48e0-bc78-f835760bbe20",
    "ExecuteTime": {
     "end_time": "2023-11-02T19:41:26.428571900Z",
     "start_time": "2023-11-02T19:41:26.020450200Z"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n                                       ('clf',\n                                        LogisticRegression(solver='liblinear'))]),\n             param_grid={'clf__C': array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n                         'clf__penalty': ['l1', 'l2']},\n             scoring='accuracy', verbose=1)",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;clf&#x27;,\n                                        LogisticRegression(solver=&#x27;liblinear&#x27;))]),\n             param_grid={&#x27;clf__C&#x27;: array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n                         &#x27;clf__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]},\n             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;clf&#x27;,\n                                        LogisticRegression(solver=&#x27;liblinear&#x27;))]),\n             param_grid={&#x27;clf__C&#x27;: array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n                         &#x27;clf__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]},\n             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;clf&#x27;, LogisticRegression(solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 7: Print out the best parameters and the best score\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best cross-validated score:\", grid_search.best_score_)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "feK_v951GgLz",
    "outputId": "a2e8b892-959d-4dc6-f2f0-094df7864733",
    "ExecuteTime": {
     "end_time": "2023-11-02T19:41:26.472963900Z",
     "start_time": "2023-11-02T19:41:26.429573300Z"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'clf__C': 11.288378916846883, 'clf__penalty': 'l1'}\n",
      "Best cross-validated score: 0.9583333333333334\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 8: Retrieve the best model from grid search\n",
    "best_model = grid_search.best_estimator_"
   ],
   "metadata": {
    "id": "YFF3ZwoCGiR9",
    "ExecuteTime": {
     "end_time": "2023-11-02T19:41:26.485006600Z",
     "start_time": "2023-11-02T19:41:26.444274300Z"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 9: Make predictions using the test set\n",
    "y_pred = best_model.predict(X_test)"
   ],
   "metadata": {
    "id": "IxY1gCNWGz-5",
    "ExecuteTime": {
     "end_time": "2023-11-02T19:41:26.485006600Z",
     "start_time": "2023-11-02T19:41:26.460007Z"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 10: Evaluate the model's performance\n",
    "cv_scores = cross_val_score(best_model, X_train, y_train, cv=5)\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Average CV Score: {cv_scores.mean()}\")\n",
    "print()\n",
    "print(\"Accuracy on test set:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oLZXFpqWG1ph",
    "outputId": "281bfaf2-eaa2-454c-b745-8fb3b710bd6d",
    "ExecuteTime": {
     "end_time": "2023-11-02T19:41:26.536183900Z",
     "start_time": "2023-11-02T19:41:26.474999200Z"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.95833333 1.         0.875      1.         0.95833333]\n",
      "Average CV Score: 0.9583333333333334\n",
      "\n",
      "Accuracy on test set: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 12: Predicting on new data\n",
    "new_data = np.array([[5.1, 3.5, 1.4, 0.2]])\n",
    "new_prediction = best_model.predict(new_data)\n",
    "print(\"Prediction for the new data:\", new_prediction)"
   ],
   "metadata": {
    "id": "po4oGeyIG8L0",
    "outputId": "1cbbf81b-b352-496b-fc05-e1867feb37a9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2023-11-02T19:41:26.538216800Z",
     "start_time": "2023-11-02T19:41:26.505646600Z"
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the new data: [0]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 13: Save the model to a file for future use\n",
    "joblib.dump(best_model, 'best_logistic_model.pkl')"
   ],
   "metadata": {
    "id": "IQ4YVk9HHBwj",
    "outputId": "f3473012-b18d-4dfc-c827-f5a9441a294c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2023-11-02T19:41:26.539235600Z",
     "start_time": "2023-11-02T19:41:26.526182500Z"
    }
   },
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "['best_logistic_model.pkl']"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "After you save your trained model to a file using joblib.dump, you would typically perform the following steps depending on your project needs:\n",
    "\n",
    "1. Deployment: If the model's performance is satisfactory, you may deploy it to a production environment where it can start making predictions on new, unseen data. This can involve setting up a REST API, using a model serving platform, or integrating it directly into an application.\n",
    "\n",
    "1. Monitoring: Once deployed, it's crucial to monitor your model to ensure it maintains performance over time and to check if it's still relevant for the data it's receiving. Monitoring can also help you detect when the model might need retraining.\n",
    "\n",
    "1. Retraining: As new data becomes available, you might retrain your model periodically with the new data to keep it up to date. This is especially important if the underlying data distribution changes over time (a phenomenon known as concept drift).\n",
    "\n",
    "1. Versioning: You should version control your model like you would with code. This means saving new versions of the model each time you retrain, so you can roll back to a previous version if necessary.\n",
    "\n",
    "1. Documentation: Documenting your model's performance metrics, the hyperparameters used, and any peculiarities noted during training/testing is vital for reproducibility and for future reference.\n",
    "\n",
    "1. Model Analysis: Sometimes, after deploying a model, you'll want to further analyze what kind of predictions it's making. Techniques like a confusion matrix, ROC curve analysis, or feature importance analysis can provide insight into how your model is operating.\n",
    "\n",
    "1. Feedback Loop: In many machine learning systems, you'll set up a feedback loop where the model's predictions are evaluated by users or domain experts, and their feedback is used to further improve the model.\n",
    "\n",
    "1. Load the Model: When you need to make predictions, you will load the model using joblib.load and then call its predict or predict_proba methods.\n",
    "\n"
   ],
   "metadata": {
    "id": "Qi0MLj5fHPFp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the saved model\n",
    "loaded_model = joblib.load('best_logistic_model.pkl')\n",
    "\n",
    "# Predict on new data\n",
    "new_data = np.array([[5.9, 3.0, 5.1, 1.8]])  # Replace this with new data\n",
    "prediction = loaded_model.predict(new_data)\n",
    "print(f\"The predicted class for the new data is: {prediction}\")"
   ],
   "metadata": {
    "id": "4G501A8nHDwp",
    "ExecuteTime": {
     "end_time": "2023-11-02T19:41:26.554458200Z",
     "start_time": "2023-11-02T19:41:26.539235600Z"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class for the new data is: [2]\n"
     ]
    }
   ]
  }
 ]
}
