{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-91e8ced48426732e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Codio Activity 8.7: Evaluating Multiple Models\n",
    "\n",
    "**Estimated Time: 120 Minutes**\n",
    "\n",
    "**Total points: 100**\n",
    "\n",
    "This assignment focuses on solving a specific regression problem using basic cross validation with a train/test/validation split.  In addition to using the methods explored, this assignment also aims to familiarize you with further utilities for data transformation including the `OneHotEncoder` and `OrdinalEncoder` along with their use in a `make_column_transformer`.  \n",
    "\n",
    "The operations of encoding categorical features will be introduced using `sklearn`.  This will allow you to streamline your model building pipelines.  Depending on whether a string type feature is **ordinal** or **categorical** we want to encode differently.  The `OrdinalEncoder` will be used to encode features that do not need to be binarized due to an underlying order, and `OneHotEncoder` for categorical features (as a similar approach to that of the `.get_dummies()` method in pandas).  By the end of the assignment, you will see how to chain multiple feature encoding methods together including the earlier `PolynomialFeatures` for numeric features. \n",
    "\n",
    "<center>\n",
    "    <img src = images/pipes.png width = 50% />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-be9e3f736326854a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Index\n",
    "\n",
    "- [Problem 1](#Problem-1)\n",
    "- [Problem 2](#Problem-2)\n",
    "- [Problem 3](#Problem-3)\n",
    "- [Problem 4](#Problem-4)\n",
    "- [Problem 5](#Problem-5)\n",
    "- [Problem 6](#Problem-6)\n",
    "- [Problem 7](#Problem-7)\n",
    "- [Problem 8](#Problem-8)\n",
    "- [Problem 9](#Problem-9)\n",
    "- [Problem 10](#Problem-10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T12:43:06.532974700Z",
     "start_time": "2023-11-23T12:43:06.366016Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#setting this will display your pipelines as seen above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bcd9a1eb3f52838e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### The Data: Ames Housing\n",
    "\n",
    "This dataset is a popular beginning dataset used in teaching regression.  The task is to use specific features of houses to predict the price of the house.  In addition to this, as discussed in video 8.10 -- this dataset is available for use in an ongoing competition where you can use the `test.csv` to submit your models predictions.  Accordingly, the two data files are identical with the exception of the `test.csv` file not containing the target feature.\n",
    "\n",
    "The data contains 81 columns of different information on the individual houses and their sale price.  A full description of the data is attached [here](data/data_description.txt).  In this assignment, you will use a small subset of the features to begin modeling with that includes ordinal, categorical, and numeric features. As an optional exercise you are encouraged to continue engineering additional features and attempt to improve the performance of your model including submitting the predictions on kaggle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T12:43:06.560332600Z",
     "start_time": "2023-11-23T12:43:06.533989500Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T12:43:06.582121400Z",
     "start_time": "2023-11-23T12:43:06.560332600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     588 non-null    object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T12:43:06.612231300Z",
     "start_time": "2023-11-23T12:43:06.570420500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n\n  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n\n  YrSold  SaleType  SaleCondition  SalePrice  \n0   2008        WD         Normal     208500  \n1   2007        WD         Normal     181500  \n2   2008        WD         Normal     223500  \n3   2006        WD        Abnorml     140000  \n4   2008        WD         Normal     250000  \n\n[5 rows x 81 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>223500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>250000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 81 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "CentralAir\nY             1365\nN               95\nName: count, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['CentralAir']].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T12:43:06.648999400Z",
     "start_time": "2023-11-23T12:43:06.585390900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T12:43:06.648999400Z",
     "start_time": "2023-11-23T12:43:06.603649500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['SalePrice']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#note the difference in one column from train to test\n",
    "[i for i in train.columns if i not in test.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4abc5a4f548e8917",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Train/Test split\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Despite having a test dataset, you want to create a holdout set to assess your models performance.  To do so, use sklearn's `train_test_split` with arguments:\n",
    "\n",
    "- `test_size = 0.3`\n",
    "- `random_state = 22`\n",
    "\n",
    "Assign your results to `X_train, X_test, y_train, y_test` below with `X` and `y` as given.  `X_train` and `X_test` should be a pandas DataFrame, and `y_train`, `y_test` are to be pandas Series.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T12:43:06.662603Z",
     "start_time": "2023-11-23T12:43:06.607449600Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train.drop('SalePrice', axis = 1)\n",
    "y = train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bc24eff90b037755",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "ExecuteTime": {
     "end_time": "2023-11-23T12:43:06.682087400Z",
     "start_time": "2023-11-23T12:43:06.612231300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1022, 80)\n",
      "(438, 80)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "X_train, X_test, y_train, y_test = '', '', '', ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=22)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(type(X_train), type(y_train))#should be DataFrame and Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n1079  1080          20       RL         65.0     8775   Pave   NaN      Reg   \n601    602          50       RM         50.0     9000   Pave   NaN      Reg   \n1015  1016          60       RL         70.0     8400   Pave   NaN      Reg   \n194    195          20       RL         60.0     7180   Pave   NaN      IR1   \n1248  1249          75       RM         60.0     9600   Pave  Grvl      Reg   \n...    ...         ...      ...          ...      ...    ...   ...      ...   \n356    357          20       RL          NaN     9248   Pave   NaN      IR1   \n960    961          20       RL         50.0     7207   Pave   NaN      IR1   \n812    813          20  C (all)         66.0     8712   Grvl   NaN      Reg   \n132    133          20       RL         75.0     7388   Pave   NaN      Reg   \n885    886         120       FV         50.0     5119   Pave   NaN      IR1   \n\n     LandContour Utilities  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n1079         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n601          Bnk    AllPub  ...         126        0    NaN   NaN         NaN   \n1015         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n194          Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n1248         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n...          ...       ...  ...         ...      ...    ...   ...         ...   \n356          Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n960          Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n812          Bnk    AllPub  ...           0        0    NaN   NaN        Shed   \n132          Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n885          Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n\n     MiscVal MoSold  YrSold  SaleType  SaleCondition  \n1079       0      4    2007        WD         Normal  \n601        0     12    2007        WD         Normal  \n1015       0     11    2009        WD         Normal  \n194        0      5    2008        WD         Normal  \n1248       0      4    2008        WD         Normal  \n...      ...    ...     ...       ...            ...  \n356        0      7    2009        WD         Normal  \n960        0      2    2010        WD         Normal  \n812       54      6    2010        WD         Alloca  \n132        0      7    2007        WD         Normal  \n885        0      1    2008       CWD        Abnorml  \n\n[1022 rows x 80 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1079</th>\n      <td>1080</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8775</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>601</th>\n      <td>602</td>\n      <td>50</td>\n      <td>RM</td>\n      <td>50.0</td>\n      <td>9000</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Bnk</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>126</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>1015</th>\n      <td>1016</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>70.0</td>\n      <td>8400</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>194</th>\n      <td>195</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>7180</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>1248</th>\n      <td>1249</td>\n      <td>75</td>\n      <td>RM</td>\n      <td>60.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>Grvl</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>356</th>\n      <td>357</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>NaN</td>\n      <td>9248</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>960</th>\n      <td>961</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>50.0</td>\n      <td>7207</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>812</th>\n      <td>813</td>\n      <td>20</td>\n      <td>C (all)</td>\n      <td>66.0</td>\n      <td>8712</td>\n      <td>Grvl</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Bnk</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Shed</td>\n      <td>54</td>\n      <td>6</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Alloca</td>\n    </tr>\n    <tr>\n      <th>132</th>\n      <td>133</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>75.0</td>\n      <td>7388</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>885</th>\n      <td>886</td>\n      <td>120</td>\n      <td>FV</td>\n      <td>50.0</td>\n      <td>5119</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2008</td>\n      <td>CWD</td>\n      <td>Abnorml</td>\n    </tr>\n  </tbody>\n</table>\n<p>1022 rows × 80 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T12:43:06.683083100Z",
     "start_time": "2023-11-23T12:43:06.619852900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "1079    126000\n601     141000\n1015    227000\n194     127000\n1248    129500\n         ...  \n356     173000\n960     116500\n812      55993\n132     150750\n885     328900\nName: SalePrice, Length: 1022, dtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T12:43:06.711195800Z",
     "start_time": "2023-11-23T12:43:06.633968200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-413dc098ce0763b8",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-23T12:43:06.976305200Z",
     "start_time": "2023-11-23T12:43:06.641099800Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X, y, test_size=0.3, random_state=22)\n",
    "#\n",
    "#\n",
    "#\n",
    "pd.testing.assert_frame_equal(X_train, X_train_), 'Make sure to set the random_state and test_size.'\n",
    "pd.testing.assert_frame_equal(X_test, X_test_)\n",
    "pd.testing.assert_series_equal(y_test, y_test_)\n",
    "pd.testing.assert_series_equal(y_train, y_train_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0a2c6ac92778897e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Baseline Predictions\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Before buildling a regression model, you should set a baseline to compare your later models to.  One way to do this is to guess the mean of the `SalePrice` column.  For the variables `baseline_train` and `baseline_test`, create arrays of same shape as `y_train` and `y_test` respectively.  These should both contain the mean of the target feature in the train set. Use the mean predictions to determine the `mean_squared_error` for both the train and test sets and assign to `mse_baseline_train` and `mse_baseline_test` below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-17a3fd0fc0eaeaad",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "ExecuteTime": {
     "end_time": "2023-11-23T12:43:06.988521Z",
     "start_time": "2023-11-23T12:43:06.845022900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1022,) (438,)\n",
      "Baseline for training data: 6277713446.182904\n",
      "Baseline for testing data: 6374354899.510017\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "baseline_train = ''\n",
    "baseline_test = ''\n",
    "mse_baseline_train = ''\n",
    "mse_baseline_test = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "baseline_train = np.ones(shape = y_train.shape)*y_train.mean()\n",
    "baseline_test = np.ones(shape = y_test.shape)*y_test.mean()\n",
    "mse_baseline_train = mean_squared_error(baseline_train, y_train)\n",
    "mse_baseline_test = mean_squared_error(baseline_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(baseline_train.shape, baseline_test.shape)\n",
    "print(f'Baseline for training data: {mse_baseline_train}')\n",
    "print(f'Baseline for testing data: {mse_baseline_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-caad282b54e71633",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-23T12:43:06.988521Z",
     "start_time": "2023-11-23T12:43:06.850138100Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X, y, test_size=0.3, random_state=22)\n",
    "baseline_train_ = np.ones(shape = y_train_.shape)*y_train_.mean()\n",
    "baseline_test_ = np.ones(shape = y_test_.shape)*y_test_.mean()\n",
    "mse_baseline_train_ = mean_squared_error(baseline_train_, y_train_)\n",
    "mse_baseline_test_ = mean_squared_error(baseline_test_, y_test_)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert mse_baseline_test == mse_baseline_test_, 'Be sure to use the train mean as your predicted value.'\n",
    "assert mse_baseline_train == mse_baseline_train_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-01d9fdafd7059e58",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Examining the Correlations\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "What feature has the highest positive correlation with `SalePrice`?  Assign your answer as a string matching the column name exactly to `highest_corr` below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eee89da304170223",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "ExecuteTime": {
     "end_time": "2023-11-23T12:43:08.595182400Z",
     "start_time": "2023-11-23T12:43:06.857357400Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'RL'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m highest_corr \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m### BEGIN SOLUTION\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m highest_corr \u001B[38;5;241m=\u001B[39m train\u001B[38;5;241m.\u001B[39mcorr()[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSalePrice\u001B[39m\u001B[38;5;124m'\u001B[39m]]\u001B[38;5;241m.\u001B[39mnlargest(columns \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSalePrice\u001B[39m\u001B[38;5;124m'\u001B[39m, n \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39mindex[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m### END SOLUTION\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Answer check\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(highest_corr)\n",
      "File \u001B[1;32mC:\\Java\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10054\u001B[0m, in \u001B[0;36mDataFrame.corr\u001B[1;34m(self, method, min_periods, numeric_only)\u001B[0m\n\u001B[0;32m  10052\u001B[0m cols \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mcolumns\n\u001B[0;32m  10053\u001B[0m idx \u001B[38;5;241m=\u001B[39m cols\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m> 10054\u001B[0m mat \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto_numpy(dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mfloat\u001B[39m, na_value\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mnan, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m  10056\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpearson\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m  10057\u001B[0m     correl \u001B[38;5;241m=\u001B[39m libalgos\u001B[38;5;241m.\u001B[39mnancorr(mat, minp\u001B[38;5;241m=\u001B[39mmin_periods)\n",
      "File \u001B[1;32mC:\\Java\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:1838\u001B[0m, in \u001B[0;36mDataFrame.to_numpy\u001B[1;34m(self, dtype, copy, na_value)\u001B[0m\n\u001B[0;32m   1836\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1837\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdtype(dtype)\n\u001B[1;32m-> 1838\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mgr\u001B[38;5;241m.\u001B[39mas_array(dtype\u001B[38;5;241m=\u001B[39mdtype, copy\u001B[38;5;241m=\u001B[39mcopy, na_value\u001B[38;5;241m=\u001B[39mna_value)\n\u001B[0;32m   1839\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m dtype:\n\u001B[0;32m   1840\u001B[0m     result \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(result, dtype\u001B[38;5;241m=\u001B[39mdtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32mC:\\Java\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1732\u001B[0m, in \u001B[0;36mBlockManager.as_array\u001B[1;34m(self, dtype, copy, na_value)\u001B[0m\n\u001B[0;32m   1730\u001B[0m         arr\u001B[38;5;241m.\u001B[39mflags\u001B[38;5;241m.\u001B[39mwriteable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   1731\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1732\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interleave(dtype\u001B[38;5;241m=\u001B[39mdtype, na_value\u001B[38;5;241m=\u001B[39mna_value)\n\u001B[0;32m   1733\u001B[0m     \u001B[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001B[39;00m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;66;03m# to further copy if copy=True or setting na_value\u001B[39;00m\n\u001B[0;32m   1736\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mno_default:\n",
      "File \u001B[1;32mC:\\Java\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1794\u001B[0m, in \u001B[0;36mBlockManager._interleave\u001B[1;34m(self, dtype, na_value)\u001B[0m\n\u001B[0;32m   1792\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1793\u001B[0m         arr \u001B[38;5;241m=\u001B[39m blk\u001B[38;5;241m.\u001B[39mget_values(dtype)\n\u001B[1;32m-> 1794\u001B[0m     result[rl\u001B[38;5;241m.\u001B[39mindexer] \u001B[38;5;241m=\u001B[39m arr\n\u001B[0;32m   1795\u001B[0m     itemmask[rl\u001B[38;5;241m.\u001B[39mindexer] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1797\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m itemmask\u001B[38;5;241m.\u001B[39mall():\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: 'RL'"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "highest_corr = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "highest_corr = train.corr()[['SalePrice']].nlargest(columns = 'SalePrice', n = 2).index[1]\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(highest_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-09461dd7ffab587a",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    },
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.595182400Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "highest_corr_ = train.corr()[['SalePrice']].nlargest(columns = 'SalePrice', n = 2).index[1]\n",
    "#\n",
    "#\n",
    "#\n",
    "assert type(highest_corr_) == type(highest_corr)\n",
    "assert highest_corr == highest_corr_, 'Make sure you have it spelled exactly as column name.'\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0a9f6ca720c9aa46",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Simple Model\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "\n",
    "Build a `LinearRegression` model on the training data using only the column `OverallQual`.  Evaluate the mean squared error on both the training and testing data, and assign these to `model_1_train_mse` and `model_1_test_mse` below.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4655883dee6d603c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "ExecuteTime": {
     "end_time": "2023-11-23T12:43:08.597901Z",
     "start_time": "2023-11-23T12:43:08.596585400Z"
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "model_1_train_mse = ''\n",
    "model_1_test_mse = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "X1 = X_train[['OverallQual']]\n",
    "lr = LinearRegression().fit(X1, y_train)\n",
    "model_1_train_mse = mean_squared_error(y_train, lr.predict(X1))\n",
    "model_1_test_mse = mean_squared_error(y_test, lr.predict(X_test[['OverallQual']]))\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(f'Train MSE: {model_1_train_mse: .2f}')\n",
    "print(f'Test MSE: {model_1_test_mse: .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-79fd3bef207ff5a5",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    },
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.596585400Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X, y, test_size=0.3, random_state=22)\n",
    "X1_ = X_train_[['OverallQual']]\n",
    "lr = LinearRegression().fit(X1_, y_train_)\n",
    "model_1_train_mse_ = mean_squared_error(y_train_, lr.predict(X1_))\n",
    "model_1_test_mse_ = mean_squared_error(y_test_, lr.predict(X_test_[['OverallQual']]))\n",
    "#\n",
    "#\n",
    "#\n",
    "assert model_1_test_mse == model_1_test_mse_, 'Test MSE is different'\n",
    "assert model_1_train_mse == model_1_train_mse_, 'Train MSE is different -- make sure not to round'\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-70c52b9e11bab667",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Using `OneHotEncoder`\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Similar to the `pd.get_dummies()` method earlier encountered, scikitlearn has a utility for encoding categorical features in the same way.  Below, the `OneHotEncoder` is demonstrated on the `CentralAir` column.  You are to use these results to build a model where the only feature is the `CentralAir` column.  Note the two arguments are used in the `OneHotEncoder`:\n",
    "\n",
    "- `sparse = False`: returns an array that we can investigate vs with `sparse = True` you are returned a sparse matrix -- a memory saving representation\n",
    "- `drop = if_binary`: returns a single column for any binary categories.  This avoids reduntant features in our regression model.\n",
    "\n",
    "Be sure to assign your fit regression model to `model_2`.  Does this model perform better than the baseline model?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.597901Z"
    }
   },
   "outputs": [],
   "source": [
    "#extract the features\n",
    "central_air_train = X_train[['CentralAir']]\n",
    "central_air_test = X_test[['CentralAir']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T12:43:08.601246Z",
     "start_time": "2023-11-23T12:43:08.598982800Z"
    }
   },
   "outputs": [],
   "source": [
    "#a categorical feature\n",
    "central_air_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.598982800Z"
    }
   },
   "outputs": [],
   "source": [
    "#Instantiate a OHE object\n",
    "#sparse = False returns an array so we can view\n",
    "ohe = OneHotEncoder(sparse = False, drop='if_binary')\n",
    "print(ohe.fit_transform(central_air_train)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.600050Z"
    }
   },
   "outputs": [],
   "source": [
    "model_2_train = ohe.fit_transform(central_air_train)\n",
    "model_2_test = ohe.transform(central_air_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eac8ef252464ca0a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.601246Z"
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "model_2 = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "model_2 = LinearRegression().fit(model_2_train, y_train)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(model_2.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8e4981dc50e33240",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-23T12:43:08.621371400Z",
     "start_time": "2023-11-23T12:43:08.602373600Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "model_2_ = LinearRegression().fit(model_2_train, y_train)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert type(model_2_) == type(model_2)\n",
    "assert model_2.coef_[0] == model_2_.coef_[0]\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc1ea1e1d6ab5e51",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "### Problem 6\n",
    "\n",
    "#### Using `make_column_transformer`\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "\n",
    "To build a model using both the `OverallQual` column and the `CentralAir` column, you could use the `OneHotEncoder` to transform `CentralAir`, and then concatenate the results back into a DataFrame or numpy array.  To streamline this process, the `make_column_transformer` can be used to seperate specific columns for certain transformations.  Below, a `make_column_transformer` has been created for you to do just this.  \n",
    "\n",
    "\n",
    "The arguments are tuples of the form `(transformer, columns)` that specify a transformation to perform on the given column.  Further, the `remainder = passthrough` argument says to just pass the other columns through.  You are returned a numpy array with the `CentralAir` column binarized and concatenated to the `OverallQual` feature.\n",
    "\n",
    "\n",
    "For an example using the `make_column_transformer` see [here](https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html#sphx-glr-auto-examples-compose-plot-column-transformer-mixed-types-py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.603923200Z"
    }
   },
   "outputs": [],
   "source": [
    "col_transformer = make_column_transformer((OneHotEncoder(drop = 'if_binary'), ['CentralAir']), remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.604953500Z"
    }
   },
   "outputs": [],
   "source": [
    "col_transformer.fit_transform(X_train[['OverallQual', 'CentralAir']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-95fca3369e308eb7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now, you can treat the `col_transformer` as a transformer object and insert it as a step in a `Pipeline`.  Below, create a `Pipeline` with the `col_transformer` as the first step, followed by `LinearRegression` estimator as `pipe_1` below.  Fit and score the pipeline on the columns `['OverallQual', 'CentralAir']`.  Does this model perform better than the baseline? \n",
    "\n",
    "- Reminder that steps in a `Pipeline` are tuples with names and objects.  You should name the transformer `col_transformer` and estimator `linreg`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7d6763d5aeaeb9d3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.605973300Z"
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "pipe_1 = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "pipe_1 = Pipeline([('col_transformer', col_transformer), ('linreg', LinearRegression())])\n",
    "pipe_1.fit(X_train[['OverallQual', 'CentralAir']], y_train)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(pipe_1.named_steps)#col_transformer and linreg should be keys\n",
    "pipe_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0680a557542d9b99",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    },
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.607140300Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X, y, test_size=0.3, random_state=22)\n",
    "pipe_1_ = Pipeline([('col_transformer', col_transformer), ('linreg', LinearRegression())])\n",
    "pipe_1_.fit(X_train_[['OverallQual', 'CentralAir']], y_train_)\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3b3b5ad3215d7c2c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "### Problem 7\n",
    "\n",
    "#### Using `OrdinalEncoder`\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Not all columns warrant binarization as done on the `CentralAir` column.  For example, consider the `HeatingQC` feature -- representing the quality of the heating in the house.  From the data description the unique values are described as:\n",
    "\n",
    "```\n",
    "HeatingQC: Heating quality and condition\n",
    "\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tAverage/Typical\n",
    "       Fa\tFair\n",
    "       Po\tPoor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-84b84d8eac1841e5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "These are ordered values, and rather than binarizing them a numeric value representing the scale can be used.  For example, using a scale of 0 - 4 you may associate the categories with an order in a list from least to greatest as:\n",
    "\n",
    "```\n",
    "['Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
    "```\n",
    "\n",
    "Creating an `OrdinalEncoder` with these categories will transform the `HeatingQC` feature mapping each category as\n",
    "\n",
    "```\n",
    "Po: 0\n",
    "Fa: 1\n",
    "TA: 2\n",
    "Gd: 3\n",
    "Ex: 4\n",
    "```\n",
    "\n",
    "This is demonstrated below, and in a similar manner the use of the `make_column_transformer` is shown using the three columns `['OverallQual', 'CentralAir', 'HeatingQC']`, applying the appropriate transformations to each column and passing the remaining numeric feature through.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.608222600Z"
    }
   },
   "outputs": [],
   "source": [
    "oe = OrdinalEncoder(categories = [['Po', 'Fa', 'TA', 'Gd', 'Ex']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.609482Z"
    }
   },
   "outputs": [],
   "source": [
    "oe.fit_transform(X_train[['HeatingQC']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.611643200Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train['HeatingQC'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.612644100Z"
    }
   },
   "outputs": [],
   "source": [
    "ordinal_ohe_transformer = make_column_transformer((OneHotEncoder(drop = 'if_binary'), ['CentralAir']),\n",
    "                                          (OrdinalEncoder(categories = [['Po', 'Fa', 'TA', 'Gd', 'Ex']]), ['HeatingQC']),\n",
    "                                          remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.613639800Z"
    }
   },
   "outputs": [],
   "source": [
    "ordinal_ohe_transformer.fit_transform(X_train[['OverallQual', 'CentralAir', 'HeatingQC']])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.614717100Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train[['OverallQual', 'CentralAir', 'HeatingQC']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-49cf07b0d3864345",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "You are to build a pipeline incorporating this new transformer and with steps named `transformer` and `linreg`.  Fit and evaluate the model on the training and test set using mean squared error.  Is this model better than the baseline? \n",
    "\n",
    "Assign your pipeline to `pipe_2` below and mean squared errors to `pipe_2_train_mse` and `pipe_2_test_mse` as floats below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-602a1345938b73cd",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.617018300Z"
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "pipe_2 = ''\n",
    "pipe_2_train_mse = ''\n",
    "pipe_2_test_mse = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "pipe_2 = Pipeline([('transformer', ordinal_ohe_transformer), \n",
    "                  ('linreg', LinearRegression())])\n",
    "pipe_2.fit(X_train[['OverallQual', 'CentralAir', 'HeatingQC']], y_train)\n",
    "pred_train = pipe_2.predict(X_train[['OverallQual', 'CentralAir', 'HeatingQC']])\n",
    "pred_test = pipe_2.predict(X_test[['OverallQual', 'CentralAir', 'HeatingQC']])\n",
    "pipe_2_train_mse = mean_squared_error(y_train, pred_train)\n",
    "pipe_2_test_mse = mean_squared_error(y_test, pred_test)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(pipe_2.named_steps)\n",
    "print(f'Train MSE: {pipe_2_train_mse: .2f}')\n",
    "print(f'Test MSE: {pipe_2_test_mse: .2f}')\n",
    "pipe_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-53707b03febb2033",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    },
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.619010700Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X, y, test_size=0.3, random_state=22)\n",
    "pipe_2_ = Pipeline([('transformer', ordinal_ohe_transformer), \n",
    "                  ('linreg', LinearRegression())])\n",
    "pipe_2_.fit(X_train[['OverallQual', 'CentralAir', 'HeatingQC']], y_train_)\n",
    "pred_train_ = pipe_2_.predict(X_train_[['OverallQual', 'CentralAir', 'HeatingQC']])\n",
    "pred_test_ = pipe_2_.predict(X_test_[['OverallQual', 'CentralAir', 'HeatingQC']])\n",
    "pipe_2_train_mse_ = mean_squared_error(y_train_, pred_train_)\n",
    "pipe_2_test_mse_ = mean_squared_error(y_test_, pred_test_)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert list(pipe_2.named_steps) == list(pipe_2_.named_steps)\n",
    "assert pipe_2_test_mse == pipe_2_test_mse_\n",
    "assert pipe_2_train_mse == pipe_2_train_mse_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e1765c6076c54a1b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "### Problem 8\n",
    "\n",
    "#### Including `PolynomialFeatures`\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Finally, the earlier transformation of continuous columns using the `PolynomialFeatures` with `degree = 2` can be implemented alongside the `OneHotEncoder` and `OrdinalEncoder`.  \n",
    "\n",
    "The `make_column_transformer` is again used, and you are to create a `Pipeline` with steps `transformer` and `linreg`.  \n",
    "\n",
    "The `Pipeline` is fit on the training data using features `['OverallQual', 'CentralAir', 'HeatingQC']`.  \n",
    "\n",
    "Your task is to determine the mean squared error on the train and test data and assign these as floats to `quad_train_mse` and `quad_test_mse` below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T12:43:08.655473100Z",
     "start_time": "2023-11-23T12:43:08.621371400Z"
    }
   },
   "outputs": [],
   "source": [
    "poly_ordinal_ohe = make_column_transformer((OrdinalEncoder(categories = [['Po', 'Fa', 'TA', 'Gd', 'Ex']]), ['HeatingQC']),\n",
    "                                           (OneHotEncoder(drop = 'if_binary'), ['CentralAir']),\n",
    "                                           (PolynomialFeatures(include_bias = False, degree = 2), ['OverallQual']))\n",
    "pipe_3 = Pipeline([('transformer', poly_ordinal_ohe), ('linreg', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.622395300Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_3.fit(X_train[['OverallQual', 'CentralAir', 'HeatingQC']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9632d89534c849f7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.623901200Z"
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "quad_train_mse = ''\n",
    "quad_test_mse = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "quad_train_preds = pipe_3.predict(X_train[['OverallQual', 'CentralAir', 'HeatingQC']])\n",
    "quad_test_preds = pipe_3.predict(X_test[['OverallQual', 'CentralAir', 'HeatingQC']])\n",
    "quad_train_mse = mean_squared_error(y_train, quad_train_preds)\n",
    "quad_test_mse = mean_squared_error(y_test, quad_test_preds)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(f'Train MSE: {quad_train_mse: .2f}')\n",
    "print(f'Test MSE: {quad_test_mse: .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a7b76d118c80b0f3",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    },
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.625347500Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "quad_train_preds_ = pipe_3.predict(X_train_[['OverallQual', 'CentralAir', 'HeatingQC']])\n",
    "quad_test_preds_ = pipe_3.predict(X_test_[['OverallQual', 'CentralAir', 'HeatingQC']])\n",
    "quad_train_mse_ = mean_squared_error(y_train_, quad_train_preds_)\n",
    "quad_test_mse_ = mean_squared_error(y_test_, quad_test_preds_)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert quad_train_mse == quad_train_mse_, 'Train MSE is different.'\n",
    "assert quad_test_mse == quad_test_mse_, 'Test MSE is different.'\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-33e878839dbe4d0c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "### Problem 9\n",
    "\n",
    "#### Including More Features\n",
    "\n",
    "**20 Points**\n",
    "\n",
    "Use the following features to build a new `make_column_transformer` and fit 5 different models of degree 1 - 5 using the `degree` argument in your `PolynomialFeatures` transformer.  Keep track of the subsequent train mean squared error and test set mean squared error with the lists `train_mses` and `test_mses` respectively.  \n",
    "\n",
    "The `poly_ordinal_ohe` object contains the different transformers needed.  Note that rather than passing a list of columns to the `PolynomialFeatures` transformer, the `make_column_selector` function is used to select any numeric feature.  For more information on the `make_column_selector` see [here](https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_selector.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.626549Z"
    }
   },
   "outputs": [],
   "source": [
    "features = ['CentralAir', 'HeatingQC', 'OverallQual', 'GrLivArea', 'KitchenQual', 'FullBath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.627573300Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.628570600Z"
    }
   },
   "outputs": [],
   "source": [
    "poly_ordinal_ohe = make_column_transformer((PolynomialFeatures(), make_column_selector(dtype_include=np.number)),\n",
    "                                           (OrdinalEncoder(categories = [['Po', 'Fa', 'TA', 'Gd', 'Ex']]), ['HeatingQC', 'KitchenQual']),\n",
    "                                               (OneHotEncoder(drop = 'if_binary', sparse = False), ['CentralAir']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5d9d938828a77c03",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.629566100Z"
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "train_mses = []\n",
    "test_mses = []\n",
    "#for degree in 1 - 5\n",
    "for i in range(1, 6):\n",
    "    #create pipeline with PolynomialFeatures degree i \n",
    "    #ADD APPROPRIATE ARGUMENTS IN POLYNOMIALFEATURES\n",
    "    poly_ordinal_ohe = make_column_transformer((PolynomialFeatures(), make_column_selector(dtype_include=np.number)),\n",
    "                                           (OrdinalEncoder(categories = [['Po', 'Fa', 'TA', 'Gd', 'Ex']]), ['HeatingQC']),\n",
    "                                               (OneHotEncoder(drop = 'if_binary'), ['CentralAir']))\n",
    "    \n",
    "    \n",
    "    #fit on train\n",
    "\n",
    "    #predict on train and test\n",
    "\n",
    "    #compute mean squared errors\n",
    "    \n",
    "    #append to train_mses and test_mses respectively\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "train_mses = []\n",
    "test_mses = []\n",
    "#for degree in 1 - 5\n",
    "for i in range(1, 6):\n",
    "    #create pipeline with PolynomialFeatures degree i\n",
    "    poly_ordinal_ohe = make_column_transformer((PolynomialFeatures(degree = i), make_column_selector(dtype_include=np.number)),\n",
    "                                           (OrdinalEncoder(categories = [['Po', 'Fa', 'TA', 'Gd', 'Ex']]), ['HeatingQC']),\n",
    "                                               (OneHotEncoder(drop = 'if_binary'), ['CentralAir']))\n",
    "    pipe = Pipeline([('transformer', poly_ordinal_ohe), ('linreg', LinearRegression())])\n",
    "\n",
    "    pipe.fit(X_train[features], y_train)\n",
    "    #fit on train\n",
    "    p1 = pipe.predict(X_train[features])\n",
    "    p2 = pipe.predict(X_test[features])\n",
    "    #predict on train and test\n",
    "    train_mses.append(mean_squared_error(y_train, p1))\n",
    "    test_mses.append(mean_squared_error(y_test, p2))\n",
    "# ### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(train_mses)\n",
    "print(test_mses)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-104b331affabd68a",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    },
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.630563500Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "train_mses_ = []\n",
    "test_mses_ = []\n",
    "#for degree in 1 - 5\n",
    "for i in range(1, 6):\n",
    "    #create pipeline with PolynomialFeatures degree i\n",
    "    poly_ordinal_ohe_ = make_column_transformer((PolynomialFeatures(degree = i), make_column_selector(dtype_include=np.number)),\n",
    "                                           (OrdinalEncoder(categories = [['Po', 'Fa', 'TA', 'Gd', 'Ex']]), ['HeatingQC']),\n",
    "                                               (OneHotEncoder(drop = 'if_binary'), ['CentralAir']))\n",
    "    pipe_ = Pipeline([('transformer', poly_ordinal_ohe_), ('linreg', LinearRegression())])\n",
    "\n",
    "    pipe_.fit(X_train[features], y_train)\n",
    "    #fit on train\n",
    "    p1_ = pipe_.predict(X_train[features])\n",
    "    p2_ = pipe_.predict(X_test[features])\n",
    "    #predict on train and test\n",
    "    train_mses_.append(mean_squared_error(y_train_, p1_))\n",
    "    test_mses_.append(mean_squared_error(y_test_, p2_))\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "assert train_mses_ == train_mses\n",
    "assert test_mses_ == test_mses\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1784752b4eea9286",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "### Problem 10\n",
    "\n",
    "#### Optimal Model Complexity \n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Based on your models mean squared error on the testing data in **Problem 9** above, what was the optimal complexity?  Assign your answer as an integer to `best_complexity` below.  Compute the **MEAN SQUARED ERROR** of this model and assign to `best_mse` as a float. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f1f08d8a16028d27",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.631560200Z"
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "best_complexity = ''\n",
    "best_mse = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "best_complexity = test_mses.index(min(test_mses)) + 1\n",
    "best_mse = min(test_mses)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(f'The best degree polynomial model is:  {best_complexity}')\n",
    "print(f'The smallest mean squared error on the test data is : {best_mse: .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e2180cfd1f8257a9",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    },
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.632944600Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "train_mses_ = []\n",
    "test_mses_ = []\n",
    "#for degree in 1 - 5\n",
    "for i in range(1, 6):\n",
    "    #create pipeline with PolynomialFeatures degree i\n",
    "    poly_ordinal_ohe_ = make_column_transformer((PolynomialFeatures(degree = i), make_column_selector(dtype_include=np.number)),\n",
    "                                           (OrdinalEncoder(categories = [['Po', 'Fa', 'TA', 'Gd', 'Ex']]), ['HeatingQC']),\n",
    "                                               (OneHotEncoder(drop = 'if_binary'), ['CentralAir']))\n",
    "    pipe_ = Pipeline([('transformer', poly_ordinal_ohe_), ('linreg', LinearRegression())])\n",
    "\n",
    "    pipe_.fit(X_train[features], y_train)\n",
    "    #fit on train\n",
    "    p1_ = pipe_.predict(X_train[features])\n",
    "    p2_ = pipe_.predict(X_test[features])\n",
    "    #predict on train and test\n",
    "    train_mses_.append(mean_squared_error(y_train_, p1_))\n",
    "    test_mses_.append(mean_squared_error(y_test_, p2_))\n",
    "\n",
    "best_complexity_ = test_mses_.index(min(test_mses_)) + 1\n",
    "best_mse_ = min(test_mses_)\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "assert int(best_complexity) == int(best_complexity_)\n",
    "assert best_mse_ == best_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-01457dafe27142fd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Further Exploration\n",
    "\n",
    "This activity was meant to introduce you to a more streamlined modeling process using the `sklearn` library.  While your models should be performing better than the baseline, it is likely that with a bit more feature engineering and cross validation you would be able to further improve the performance.  You are encouraged to explore further feature engineering and encoding, particularly with handling missing values.  \n",
    "\n",
    "Additionally, other transformations on the data may be appropriate.  For example, if you look at the distribution of errors in your model, you will note that they are slightly skewed.  An assumption of a Linear Regression model is that these should be roughly normally distributed.  By building a model on the logarithm of the target column, and evaluating the model on the logarithm of the testing data you will improve towards this assumption.  Note that the actual kaggle exercise is judged on the **ROOT MEAN SQUARED ERROR** of the logarithm of the target feature. \n",
    "\n",
    "If interested, scikitlearn also provides a function `TransformedTargetRegressor` that will accomplish this transformation and can easily be added to a pipeline. See [here](https://scikit-learn.org/stable/modules/generated/sklearn.compose.TransformedTargetRegressor.html) for more information on this transformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-23T12:43:08.633949200Z"
    }
   }
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
